<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: server | @Lenciel]]></title>
  <link href="http://lenciel.com/categories/server/atom.xml" rel="self"/>
  <link href="http://lenciel.com/"/>
  <updated>2017-04-01T18:13:22+08:00</updated>
  <id>http://lenciel.com/</id>
  <author>
    <name><![CDATA[Lenciel]]></name>
    <email><![CDATA[lenciel@gmail.com]]></email>
  </author>

  
  <entry>
    <title type="html"><![CDATA[解决iowait过高的告警]]></title>
    <link href="http://lenciel.com/2014/02/hunting-the-iowait-problem-maker/"/>
    <updated>2014-02-24T09:22:00+08:00</updated>
    <id>http://lenciel.com/2014/02/hunting-the-iowait-problem-maker</id>
    <content type="html"><![CDATA[<p><img src="/downloads/images/2014_02/warning_letter.png" title="Don't touch me..." alt="warning letter" /></p>

<p>从Nagios切到<a href="https://www.zabbix.com">Zabbix</a>之后，经常大清早被iowait过高的告警邮件叫醒。因为这套Zabbix监控是本座搭的，所以解决这个问题就只有本座来了&hellip;..哎，不知道是不是把首席运营官给宠坏了。</p>

<a name="iowait........................"></a>
<h2>iowait的定义和计算方式</h2>

<p>iowait的定义为：</p>

<p><blockquote><p>iowait is time that the processor/processors are waiting (i.e. is in an idle state and does nothing), during which there in fact was outstanding disk I/O requests.</p></blockquote></p>

<p>也就是至少有一个I/O在进行时CPU处于<code>idle</code>状态的比例。</p>

<p>我们都知道用<code>vmstat</code>, <code>iostat</code>, <code>sar</code>等命令查看系统状况的时候，CPU有四种比较主要的状态：user, sys, idle和iowait。它们都是表示CPU处于此状态的一个平均比例（其中sar命令是可以用<code>-P</code>具体指定哪个CPU的，其他的命令一般是所有CPU的平均），通常相加应该就是1.</p>

<p>这个比例的统计其实是通过kernel不断的更新计数器然后计算出来的。当时钟中断发生的时候，kernel检查当前CPU是不是idle的。如果不是，就检查正在执行的指令是user space还是kernel space的。如果是user space就给<code>user</code>的计数器加1，kernel space就给<code>sys</code>计数器加1.</p>

<p>类似的，如果CPU是处于idle状态，kernel就检查是不是有I/O操作正在发生（可以是local disk也可以是<code>mount</code>的NFS），如果有就给<code>iowait</code>计数器加1，没有就给<code>idle</code>计数器加1.</p>

<p>当我们运行<code>vmstat</code>或者<code>sar</code>等命令查看时，它们会先读取当前这几个计数器的计数，然后在用户指定的时间里面等待，然后再次读取。因为用户指定的时间里面过去了多少个<code>tick</code>是可以计算的，然后前后计数器的增值也可以计算，就可以算出一个比值。比如如果用户运行的命令是<code>vmstat 2</code>，表示每两秒取样一次，那么：</p>

<ol>
<li>tick是10ms一个，所以总共是200个ticks</li>
<li>计数器的增量/200*100就是每个状态的百分比</li>
</ol>


<a name="iowait........."></a>
<h2>iowait的意义</h2>

<p>这其实比它怎么计算要难理解一些。比如本座之前心里就有一个疑问：既然只是某个process在block，那么系统会schedule其他的事情，这对性能有什么大不了的影响呢？</p>

<p>来看几个例子。</p>

<a name="L........."></a>
<h3>例子一</h3>

<p>假设一个程序进行批量的事务，每个事务都有一个10ms的计算任务，计算出的结果通过同步的方式写到磁盘。由于它写结果的文件是阻塞方式打开的，所以I/O完成之前写操作是不会<code>return</code>的。如果我们假设磁盘系统没有cache，每个物理的I/O需要20ms，那么一个事务需要30ms。也就是每秒33个事务（33 tps）。如果把系统算成只有一个CPU的话，很显然<code>iowait</code>就是66%。</p>

<p>这种情况下，如果我们能改进I/O子系统，比如启用磁盘的缓存，让每次物理的I/O只需要1ms的话，那么<code>iowait</code>就会迅速下降到8%左右。可见这种情况下，<code>iowait</code>直接影响着程序的performance。</p>

<a name="L........."></a>
<h3>例子二</h3>

<p>假设一个磁盘检查的程序运行在系统上，每秒钟读4k的数据。我们假设这个程序的入口是main()，然后读磁盘的函数是read()，main()和read()都是用户态的。read()属于libc.a，会调用kread()这个系统调用来进行物理的I/O，这个时候就进入了kernel态。整个main(),read()和kread执行的时间加起来不长，我们假设是50微秒。而物理的I/O需要多久要看seek的数据有多远，假设需要2-20ms。这样就完全有可能当时钟中断的时候，cpu是idle的，而且I/O正在发生，于是<code>iowait</code>值就达到97-98% (如果每个I/O需要20ms就是99-100%)。</p>

<p>这种情况下，虽然<code>iowait</code>数值非常高，其实这个系统的性能是正常的。</p>

<a name="L........."></a>
<h3>例子三</h3>

<p>假设有两个程序跑在同一个CPU上。一个程序写得有点儿问题，I/O会阻塞10秒左右。另一个则100%的时间都在做计算。由于当前一个程序阻塞起来的时候，后面这个程序被运行了，因此无论什么时候都没有CPU处于idle的状态等I/O，于是<code>iowait</code>一直是0，这时候其实系统的performance是有很大的问题的。</p>

<a name="L........."></a>
<h3>例子四</h3>

<p>假设系统是4核的CPU，运行了6个程序。其中4个程序有70%时间在进行物理的I/O，30%的时间在进行计算任务（假设其中25%在用户态，5%在kernel态）。另外2个程序假设100%时间都在用户态进行计算任务，没有任何I/O操作。</p>

<p>如果我们查看系统的CPU状态，大概可能看到下面的状况:</p>

<pre><code>     cpu    %usr    %sys    %iowait   %idle
      0       50      10      40       0
      1       50      10      40       0
      2      100       0       0       0
      3      100       0       0       0
      -       75       5      20       0
</code></pre>

<p>如果我们把相同的6个程序跑到一个6核的机器（相同的CPU和磁盘配置），那么可以简单的认为会有下面的结果：</p>

<pre><code>     cpu    %usr    %sys    %iowait   %idle
      0       25       5      70       0
      1       25       5      70       0
      2       25       5      70       0
      3       25       5      70       0
      4      100       0       0       0
      5      100       0       0       0
      -       50       3      47       0
</code></pre>

<p>也就是说，同样的程序跑在不同的系统上，iowait增加了一倍多，而这个时候其实没有什么performance问题，只不过是系统还能做更多的计算工作。</p>

<a name="L......"></a>
<h3>结论</h3>

<ul>
<li>CPU处于<code>iowait</code>状态，并不说明CPU不能运行其他的程序</li>
<li><code>iowait</code>偏高只能说明系统这个时刻还能进行更多的计算任务，至于是不是出现了performance问题，需要进一步分析才知道</li>
</ul>


<a name="L..........................."></a>
<h2>找出造成问题的进程</h2>

<p>虽然每次都是6点半多少说明应该是某个cron任务（因为机器上没有其他自定义的定时任务）但没法具体知道究竟是哪个。</p>

<p>最简单的办法当然是出问题的时候用<code>iotop</code>命令来看了 。</p>

<pre><code> # iotop
 Total DISK READ: 8.00 M/s | Total DISK WRITE: 20.36 M/s
  TID PRIO USER DISK READ DISK WRITE SWAPIN IO&gt; COMMAND
 15758 be/4 root 7.99 M/s 8.01 M/s 0.00 % 61.97 % bonnie++ -n 0 -u 0 -r 239 -s 478 -f -b -d /tmp
</code></pre>

<p>但是谁又会在6点多起来干这种事情。除开修改系统时间重现问题，还可以通过ps命令查看记录处于<code>D</code>状态的进程来找到。</p>

<p><code>ps</code>命令输出里面对<code>PROCESS STATE CODES</code>的定义是：</p>

<pre><code> D uninterruptible sleep (usually IO)
 R running or runnable (on run queue)
 S interruptible sleep (waiting for an event to complete)
 T stopped, either by a job control signal or because it is being traced.
 W paging (not valid since the 2.6.xx kernel)
 X dead (should never be seen)
 Z defunct ("zombie") process, terminated but not reaped by its parent.
</code></pre>

<p>处于等待I/O完成状态的进程一般就是<code>D</code>，所以可以通过tmux起一个sessio来跑下面的命令：</p>

<pre><code>    while true; do date; ps auxf | awk '{if($8=="D") print $0;}'; sleep 1; done &gt; /var/log/ps.log
</code></pre>

<p>然后在又一个这样的6点半：</p>

<p><img src="/downloads/images/2014_02/zabbix_cpu_util.png" title="Don't touch me..." alt="warning letter" /></p>

<p>去日志里面查看：</p>

<pre><code>$ cat /var/log/ps.log | grep D

root      7585  7.9  0.0   5904   812 ?        D    06:34   0:02                  \_ /usr/bin/updatedb.mlocate
root      7585  7.8  0.0   5904   812 ?        D    06:34   0:02                  \_ /usr/bin/updatedb.mlocate
root      7585  7.8  0.0   5904   812 ?        D    06:34   0:02                  \_ /usr/bin/updatedb.mlocate
root      7585  7.8  0.0   5944   944 ?        D    06:34   0:02                  \_ /usr/bin/updatedb.mlocate
root      7585  7.7  0.0   5944   944 ?        D    06:34   0:02                  \_ /usr/bin/updatedb.mlocate
root      7585  7.5  0.0   5944   944 ?        D    06:34   0:02                  \_ /usr/bin/updatedb.mlocate
root      7585  7.5  0.0   5944   944 ?        D    06:34   0:02                  \_ /usr/bin/updatedb.mlocate
root      7585  7.6  0.0   5944   944 ?        D    06:34   0:03                  \_ /usr/bin/updatedb.mlocate
root      7585  7.7  0.0   5944   944 ?        D    06:34   0:03                  \_ /usr/bin/updatedb.mlocate
root      7585  7.7  0.0   5944   944 ?        D    06:34   0:03                  \_ /usr/bin/updatedb.mlocate
root      7585  7.8  0.0   5944   944 ?        D    06:34   0:03                  \_ /usr/bin/updatedb.mlocate
root      7585  7.7  0.0   5944   944 ?        D    06:34   0:03                  \_ /usr/bin/updatedb.mlocate
root      7585  7.8  0.0   5944   944 ?        D    06:34   0:03                  \_ /usr/bin/updatedb.mlocate
root      7585  7.7  0.0   5944   944 ?        D    06:34   0:03                  \_ /usr/bin/updatedb.mlocate
root      7585  7.7  0.0   5944   944 ?        D    06:34   0:03                  \_ /usr/bin/updatedb.mlocate
root      7585  7.7  0.0   5944   944 ?        D    06:34   0:03                  \_ /usr/bin/updatedb.mlocate
root      7585  7.7  0.0   5944   944 ?        D    06:34   0:03                  \_ /usr/bin/updatedb.mlocate
root      7585  7.8  0.0   5944   944 ?        D    06:34   0:03                  \_ /usr/bin/updatedb.mlocate
root      7585  7.8  0.0   5944   944 ?        D    06:34   0:03                  \_ /usr/bin/updatedb.mlocate
root      7585  7.8  0.0   5944   944 ?        D    06:34   0:04                  \_ /usr/bin/updatedb.mlocate
root      7585  7.6  0.0   5944   944 ?        D    06:34   0:04                  \_ /usr/bin/updatedb.mlocate
root      7585  7.6  0.0   5944   944 ?        D    06:34   0:04                  \_ /usr/bin/updatedb.mlocate
root      7585  7.6  0.0   5944   944 ?        D    06:34   0:04                  \_ /usr/bin/updatedb.mlocate
root      7585  7.6  0.0   5944   944 ?        D    06:34   0:04                  \_ /usr/bin/updatedb.mlocate
root      7585  7.7  0.0   5944   944 ?        D    06:34   0:04                  \_ /usr/bin/updatedb.mlocate
root      7585  7.6  0.0   5944   944 ?        D    06:34   0:04                  \_ /usr/bin/updatedb.mlocate
root      7585  7.6  0.0   6000   968 ?        D    06:34   0:04                  \_ /usr/bin/updatedb.mlocate
root      7585  7.6  0.0   6000   968 ?        D    06:34   0:04                  \_ /usr/bin/updatedb.mlocate
</code></pre>

<p>嗯，原来是<code>/usr/bin/updatedb.mlocate</code>。Google了一下<a href="" title="http://ubuntuforums.org/showthread.php?t=1243951&amp;page=2&amp;p=7844783#post7844783">^1</a>发现其实关掉也没什么：</p>

<pre><code>sudo killall updatedb.mlocate
sudo chmod -x /etc/cron.daily/mlocate
</code></pre>

<p>整个世界清静了。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[uWSGI, Gunincorn, 啥玩意儿?]]></title>
    <link href="http://lenciel.com/2013/08/why-you-need-something-like-gunicorn/"/>
    <updated>2013-08-01T14:36:00+08:00</updated>
    <id>http://lenciel.com/2013/08/why-you-need-something-like-gunicorn</id>
    <content type="html"><![CDATA[<p>因为nginx等优秀的开源项目，有不少本来不是做服务器的同学也可以写很多服务器端的程序了。但是在聊天中会发现，大家虽然写了不少代码，但是对wsgi是什么，gunicorn是什么，反向代理又是什么并不了解，也就是说对基本概念并没有一个全局的了解。</p>

<a name="L........."></a>
<h3>服务器</h3>

<p>到了服务器组你会发现原来有各种各样的服务器，那些叫法很多是有历史沉淀的，不需要太深究能对上号就行，因为本来也是乱七八糟的。</p>

<a name="HTTP........."></a>
<h4>HTTP服务器</h4>

<p>如果网站是HTML/CSS/JS（不包括node.js这种<a href="http://en.wikipedia.org/wiki/Comparison_of_server-side_JavaScript_solutions">SSJS</a>）组成的，那么这是一个静态的网站。</p>

<p>用户访问这个网站的时候，HTTP请求被浏览器发送，经过DNS等被送到网站的服务器。服务器处理HTTP请求，将浏览器能够处理的响应返回给用户的浏览器。所以这个场景下的服务器一般被称为HTTP服务器，常见的有Apache的httpd和Nginx。</p>

<a name="Application........."></a>
<h4>Application服务器</h4>

<p>如果你的网站是动态的，比如是用Django写的。</p>

<p>那么客户端上来的请求要能够被Djano的Application处理。WSGI就是这样的<a href="http://en.wikipedia.org/wiki/Web_Server_Gateway_Interface">一个协议</a>：它是一个Python程序和用户请求之间的接口。WSGI服务器的作用就是接受并分析用户的请求，调用相应的python对象完成对请求的处理，然后返回相应的结果。</p>

<p>WSGI服务器的选择很多，包括uWSGI和gunicorn。它们都可以处理所有的请求，包括确实应该由python对象处理的，也包括不该python对象处理的，比如静态的图像，css，js等文件。所以理论上你可以把整个动态网站都用WSGI服务器承载起来，也就是整个应用完全跑在Application服务器上。</p>

<a name="L..............."></a>
<h4>代理服务器</h4>

<p>代理无非是A来做B干的事情。在服务器语境下，代理就是一台服务器干另外一台服务器的事情。这个是平常不会有很多人聊到的，多说两句。</p>

<a name="L....................."></a>
<h5>前向代理服务器</h5>

<p>大多数的代理都是前向代理。假设网络上有三台机器:</p>

<ul>
<li>X：你的电脑</li>
<li>Y：代理服务器，proxy.eg.org</li>
<li>Z：你实际想访问的服务器，www.eg.org</li>
</ul>


<p>没有代理的情况下，访问是 <code>X---&gt;Z</code>，但是在某些情况下，访问者会先让代理服务器从实际放内容的服务器把数据取回来，也就是<code>X---&gt;Y</code>，然后<code>Y----&gt;Z</code>，最后<code>X----&gt;Y</code> 。</p>

<p>这里说的某些情况下典型的包括（作为天朝网民你居然没有领悟我很失望）：</p>

<p>X的网络管理员封了Z</p>

<ul>
<li>Z可能是一个臭名昭著的病毒网站：<code>familypostcard2008.com</code>等</li>
<li>Z可能是一个让你上班精力分散的网站：<code>Facebook.com</code>等</li>
<li>Z可能是一个让你明白真相的网站：Hmmmm</li>
</ul>


<p>Z的网络管理员封了X</p>

<ul>
<li>Z可能是一个论坛或者blog什么的，X在对它进行扫描</li>
</ul>


<a name="L....................."></a>
<h5>反向代理服务器</h5>

<p>没有代理的情况下，访问仍然是 <code>X---&gt;Z</code>，但是在某些情况下，Z的管理者决定限制资源被直接访问。用户必须现在Y上做访问，Y再访问Z。整个流程是<code>X---&gt;Y</code>，然后<code>Y----&gt;Z</code>，最后<code>X----&gt;Y</code> 。</p>

<p>没错，细心的你注意到了，前向和反向代理服务器的流程都是<code>X--&gt;Y--&gt;Z</code>。没办法，代理就是这么个意思。它们两者的核心区别在于，用户对反向代理服务器的存在是无感的。换句话说，X不需要做特别的配置甚至不需要察觉Y的存在，就可以使用Y这个反向代理。这种请求方无感而被请求方反过来提供代理服务就是“反向”的意义所在。</p>

<p>使用反向代理的典型场景当然是Z希望所有发给自己特定请求都从Y过一遍：</p>

<ol>
<li>Z可能是一个超大的网站，每天有全世界各地的用户在访问。于是Z搭建了一个反向代理，把某个地域的用户的访问导入到离他最近的服务器上去处理。没有错，这就是CDN。</li>
<li>Z可能是一个坏坏的网站。它的拥有者希望把坏坏的数据放到特定的服务器，然后核心数据放到别的服务器。比如黄色网站，一般那些色情的内容放在一些专门的服务器上，即使被查封，也不会对其业务产生决定性的影响。</li>
</ol>


<p>继续我们前面的例子，很快你会发现uWSGI等应用服务器处理静态文件的请求的performance很废材，于是开始寻找直接用nginx来处理静态内容的办法。那么你就需要区分哪些请求是请求的静态页面，哪些是请求的动态内容。</p>

<p>然后你就会发现，原来nginx不止是一个HTTP服务器，它还是一个<a href="http://en.wikipedia.org/wiki/Reverse_proxy">反向代理服务器</a>：它可以把请求重定向到uWSGI或者任何别的服务器，然后把下游服务器的响应集成再返回给用户。于是你就可以配置对静态内容的请求直接在nginx完成，而动态内容的请求发送给uWSGI服务器。</p>

<a name="L....................."></a>
<h4>负载均衡服务器</h4>

<p>在我自己的心中，负责均衡服务器不过是反向代理的一种（你看CDN我也觉得是反向代理的一种），但是很多地方这种服务器是被拿出来专门讨论的。</p>

<p>随着你的网站访问量不断增大，你用一个nginx集中所有的请求再分发就显得性能不够了。这个时候你可以配置专门用于进行请求分发处理的负载均衡服务器，比如<a href="http://haproxy.1wt.eu/">HAProxy</a>，而负载均衡服务器背后是集群。</p>

<a name="L..............."></a>
<h4>缓存服务器</h4>

<p>随着网站访问量的继续增大，你的VPS流量又扛不住了。你调查发现有一些多媒体文件被经常请求，这个时候你部署了缓存服务器。</p>

<p>&ldquo;缓存"这个经常被提到的术语，核心就是把常用的信息放在一个读取成本很低地方(比如内存中或者是虚拟内存中），从而避免每次查找它的时候昂贵的操作。比如HTTP缓存解决的是在服务器上找信息的过程，而Redis或者Memcached这些缓存则是解决在数据库里面找信息的过程。</p>

<a name="L...........................uwsgi......gunicorn."></a>
<h3>那，我们为什么需要uwsgi或者gunicorn?</h3>

<p>一句话：因为你需要有东西在服务器上运行Python，但是Python不是处理所有的请求都很强。</p>

<p>那么是选uWSGI还是Gunicorn？我觉得都可以，还是那句老话，不是它们好不好的问题，是你够不够好的问题，毕竟代码都摆在那里的。</p>

<p>不过Gunicorn可以多说几句。它的崛起在我看来是有时代背景的：在过去，我们部署一个应用的时候，几乎总是要分布在多台机器的（比如4台HTTP服务器把动态请求分发到两台Application服务器上，并且它们都访问一个数据库服务器）。但是随着机器的能力在增强，而互联网应用的覆盖面从业务逻辑极其复杂的银行业电信业到了送盒饭选泡面的小行业，越来越多的Application服务器和Web服务器合体了（以django圈子举例，有httpd+mod_wsgi或者Nginx+mod_uwsgi）。而且很多时候这种小应用的数据库也host在同一台机器上。</p>

<p>Gunicorn（从Ruby下面的Unicorn得到的启发）应运而生：依赖Nginx的代理行为，同Nginx进行功能上的分离。由于不需要直接处理用户来的请求（都被Nginx先处理），Gunicorn不需要完成相关的功能，其内部逻辑非常简单：接受从Nginx来的动态请求，处理完之后返回给Nginx，由后者返回给用户。</p>

<p>由于功能定位很明确，Gunicorn得以用纯Python开发：大大缩短了开发时间的同时，性能上也不会很掉链子。同时，它也可以配合Nginx的代理之外的别的Proxy模块工作，其配置也相应比较简单。</p>

<p>配置上的简单，大概是它流行的最大的原因。</p>

<a name="Good.Refs"></a>
<h3>Good Refs</h3>

<a name="L..........................."></a>
<h4>正向代理服务器软件</h4>

<ul>
<li><a href="http://www.jmarshall.com/tools/cgiproxy/">cgi-proxy</a></li>
<li><a href="http://sourceforge.net/projects/poxy">phproxy</a> (中断了)</li>
<li><a href="http://www.glype.com/">glype</a></li>
<li><a href="http://en.cship.org/wiki/Category%3aWebproxy">Internet censorship wiki: List of Web Proxies</a></li>
</ul>


<a name="L..........................."></a>
<h4>反向代理服务器软件</h4>

<ul>
<li><a href="http://wiki.apache.org/cocoon/ApacheModProxy">apache mod_proxy</a></li>
<li><a href="http://www.squid-cache.org/">squid</a></li>
<li><a href="http://nginx.net/">HAProxy</a></li>
<li><a href="http://www.danga.com/perlbal/">perlbal</a></li>
<li><a href="http://portfusion.sf.net/">portfusion</a></li>
<li><a href="http://www.apsis.ch/pound/">pound</a></li>
</ul>


<a name="TCP................................."></a>
<h4>TCP上的反向代理服务器软件</h4>

<ul>
<li><a href="http://www.inlab.de/balance.html">balance</a></li>
<li><a href="http://www.delegate.org/delegate/nvproxy/">delegate</a></li>
<li><a href="http://siag.nu/pen/">pen</a></li>
<li><a href="http://portfusion.sf.net/">portfusion</a></li>
<li><a href="http://web.archive.org/web/20080113185334/http://plb.sunsite.dk/index.html">pure load balancer</a></li>
<li><a href="http://pythondirector.sourceforge.net/">python director</a></li>
</ul>


<a name="L......"></a>
<h4>其他</h4>

<ul>
<li><a href="http://en.wikipedia.org/wiki/Content_Delivery_Network">Wikipedia - Content Delivery Network</a></li>
<li><a href="http://en.wikipedia.org/wiki/Category%3aReverse_proxy">Wikipedia - Category:Reverse_proxy</a></li>
<li><a href="http://en.wikipedia.org/wiki/Load_balancing_%28computing%29">Wikipedia - Load Balancing</a></li>
<li><a href="http://en.wikipedia.org/wiki/Scalability">Wikipedia - Scalability</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[First steps on a new server]]></title>
    <link href="http://lenciel.com/2013/04/first-steps-on-a-new-server/"/>
    <updated>2013-04-04T08:44:00+08:00</updated>
    <id>http://lenciel.com/2013/04/first-steps-on-a-new-server</id>
    <content type="html"><![CDATA[<p>一般来说，新开张的小团队不会养专职的运维和部署团队。一般服务器开发的项目组会有人兼职做这部分的事情。刚开始的时候这部分的工作量一般也不大，但是随着租用的服务器越来越多，兼职的人就会发现自己是在打上甘岭战役————坡越来越陡。</p>

<p>因此，一个简单而有效的标准流程是非常必要的。ZooM团队的服务器都会配置两个固定的帐号： <code>root</code> 和 <code>deploy</code> 。 <code>deploy</code>  这个用户具有 <code>sudo</code> 的权限。开发人员使用deploy但是不通过用户名密码登录而是用 <code>public key</code> 。这样一来，只需要保证所有机器的 <code>authorized_keys</code> 文件同步即可。后面要做的改进是：</p>

<ul>
<li>在所有机器禁止通过 root 账号进行ssh</li>
<li>在所有机器上限制可以ssh的IP范围</li>
</ul>


<p>这样的实施方案对 <code>authorized_keys</code> 的保密性和正确性要求是很高的，但是在没有专门IT的时候，对我们这样的小团队基本是够用的。下面是详细的步骤：</p>

<p>我们拿到的第一台机器是Ubuntu的，因为 <code>Gitlab</code> 只有Debian的版本。后面的机器大多会是CentOS，所以使用的命令可能会稍微有调整，但是意思是不变的。</p>

<a name="L......root......"></a>
<h2>更换root密码</h2>

<pre><code class="bash">passwd
</code></pre>

<p>可以很长很复杂（反正也不需要记得），保存在某个地方在你忘记 <code>sudo</code> 密码或者是不能正常 <code>ssh</code> 的时候能找出来用就可以了。</p>

<a name="L............"></a>
<h2>更新系统</h2>

<pre><code class="bash">apt-get update
apt-get upgrade
</code></pre>

<a name="L......Fail2ban"></a>
<h2>安装Fail2ban</h2>

<pre><code class="bash">apt-get install fail2ban
</code></pre>

<p>Fail2ban是一个用来监控登录尝试的 <code>daemon</code> ，可以有效侦测和防止可疑行为的发生。这个工具文档很全，而且出厂配置就很齐全，几乎不需要定制就能投入使用了。</p>

<a name="L......deploy......"></a>
<h2>添加deploy用户</h2>

<pre><code class="bash">useradd deploy
mkdir /home/deploy
mkdir /home/deploy/.ssh
chmod 700 /home/deploy/.ssh
</code></pre>

<a name="L........code.public.key..code.."></a>
<h2>配置 <code>public key</code> </h2>

<p>使用密码的日子已经慢慢过时了，这方面Github很有<a href="https://help.github.com/categories/56/articles">贡献</a>。只需要：</p>

<pre><code class="bash">vim /home/deploy/.ssh/authorized_keys
</code></pre>

<p>把 <code>id_rsa.pub</code> 的内容拷贝进去。然后：</p>

<pre><code class="bash">chmod 400 /home/deploy/.ssh/authorized_keys
chown deploy:deploy /home/deploy -R
</code></pre>

<p>当然你也可以使用 <code>id_rsa.pub</code> 之外的key，然后在本地的 <code>~/.ssh/config</code> 里面对 <code>IdentityFile</code> 做指定。具体方式可以查看 <code>~/.ssh/config</code>的说明。</p>

<a name="L......deploy.................code.Sudo..code........"></a>
<h2>测试deploy用户并赋予 <code>Sudo</code> 权限</h2>

<p>先测试deploy是否能够正常登录，然后使用 <code>root</code> 账号设置密码：</p>

<pre><code class="bash">passwd deploy
</code></pre>

<p>这是团队要用来 <code>sudo</code> 的账号，所以要弄得有意义好记一点儿。接下来：</p>

<pre><code class="bash">visudo
</code></pre>

<p>注释掉所以已经存在的用户、用户组权限，然后加上：</p>

<pre><code class="bash">root    ALL=(ALL) ALL
deploy  ALL=(ALL) ALL
</code></pre>

<a name="L......SSH"></a>
<h2>锁定SSH</h2>

<p>设置ssh，禁止使用密码ssh，禁止使用 <code>root</code> 账号ssh。</p>

<pre><code class="bash">vim /etc/ssh/sshd_config
</code></pre>

<p>添加下面的设置：</p>

<pre><code class="bash">PermitRootLogin no
PasswordAuthentication no
</code></pre>

<p>如果有需要还可以限定可以ssh的ip地址：</p>

<pre><code class="bash">AllowUsers deploy@(your-ip) deploy@(another-ip-if-any)
</code></pre>

<p>重启ssh：</p>

<pre><code class="bash">service ssh restart
</code></pre>

<a name="L..............."></a>
<h2>设置防火墙</h2>

<p>Ubuntu提供了 <code>ufw</code>，所以只需要：</p>

<pre><code class="bash">ufw allow from {your-ip} to any port 22
ufw allow 80
ufw allow 443
ufw enable
</code></pre>

<a name="L........................"></a>
<h2>打开自动安全更新</h2>

<p>虽然很多习惯好的服务器使用者会知道运行<code>apt-get update/upgrade</code> 但是如果服务器很多，总会有一些不那么被经常登录的机器，系统会比较陈旧。特别是做负载均衡的机器，可能很少有人登录。为了保证所有的机器都有足够的安全性需要打开自动更新（作为习惯控制一切的开发人员，自动更新总是一件让我很抗拒的事情，但是安全漏洞更让人抗拒）：</p>

<pre><code class="bash">apt-get install unattended-upgrades
vim /etc/apt/apt.conf.d/10periodic
</code></pre>

<p>在文件里面修改成：</p>

<pre><code class="bash">APT::Periodic::Update-Package-Lists "1";
APT::Periodic::Download-Upgradeable-Packages "1";
APT::Periodic::AutocleanInterval "7";
APT::Periodic::Unattended-Upgrade "1";
</code></pre>

<p>接着修改：</p>

<pre><code class="bash">vim /etc/apt/apt.conf.d/50unattended-upgrades
</code></pre>

<p>修改文件成：</p>

<pre><code class="bash">Unattended-Upgrade::Allowed-Origins {        
    "Ubuntu lucid-security";
    //"Ubuntu lucid-updates"; 只更新安全更新
};
</code></pre>

<a name="L......Logwatch"></a>
<h2>安装Logwatch</h2>

<p>Logwatch是一个监控你的日志并发送邮件通知的daemon。</p>

<pre><code class="bash">apt-get install logwatch
vim /etc/cron.daily/00logwatch
</code></pre>

<p>在文件中添加：</p>

<pre><code class="bash">/usr/sbin/logwatch --output mail --mailto lenciel@gmail.com --detail high
</code></pre>

<a name="What.s.Next"></a>
<h2>What&rsquo;s Next</h2>

<ul>
<li>使用Puppet自动化这些配置</li>
<li>在基础的配置上，把一个fresh的机器如果配置成各种形态的（Django/Web/Database/LoadBalance/&hellip;)</li>
</ul>

]]></content>
  </entry>
  
</feed>
