<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: linux | @Lenciel]]></title>
  <link href="http://172.16.121.110:4000/categories/linux/atom.xml" rel="self"/>
  <link href="http://172.16.121.110:4000/"/>
  <updated>2017-04-06T19:01:30+08:00</updated>
  <id>http://172.16.121.110:4000/</id>
  <author>
    <name><![CDATA[Lenciel]]></name>
    <email><![CDATA[lenciel@gmail.com]]></email>
  </author>

  
  <entry>
    <title type="html"><![CDATA[Openssl Heartbleed Bug]]></title>
    <link href="http://172.16.121.110:4000/2014/04/openssl-heartbleed-bug/"/>
    <updated>2014-04-10T11:29:15+08:00</updated>
    <id>http://172.16.121.110:4000/2014/04/openssl-heartbleed-bug</id>
    <content type="html"><![CDATA[<p>连某宝都中招的<a href="http://heartbleed.com/">Heartbleed bug</a>究竟是个什么东西？简单地说就是攻击者可以读最多64KB内存的内容。</p>

<p>读了这64KB能干嘛？用报这个bug的人的话来说：</p>

<p><blockquote><p>Without using any privileged information or credentials we were able steal from ourselves the secret keys used for our X.509 certificates, user names and passwords, instant messages, emails and business critical documents and communication.</p></blockquote></p>

<p>那么读取64KB内存和获取这么多关键信息究竟有什么关系呢？</p>

<a name="The.bug"></a>
<h2>The bug</h2>

<p>先来看看<a href="http://git.openssl.org/gitweb/?p=openssl.git;a=commitdiff;h=96db9023b881d7cd9f379b0c154650d6c108e9a3">patch</a>里面的<code>ssl/d1_both.c</code>:</p>

<pre><code class="c">int            
dtls1_process_heartbeat(SSL *s)
    {          
    unsigned char *p = &amp;s-&gt;s3-&gt;rrec.data[0], *pl;
    unsigned short hbtype;
    unsigned int payload;
    unsigned int padding = 16; /* Use minimum padding */
</code></pre>

<p>可以看到，heartbeat里有一个 <a href="http://en.wikipedia.org/wiki/Transport_Layer_Security">SSLv3</a>  record的指针，这个<code>record</code>的代码如下:</p>

<pre><code class="c">typedef struct ssl3_record_st
    {
        int type;               /* type of record */
        unsigned int length;    /* How many bytes available */
        unsigned int off;       /* read/write offset into 'buf' */
        unsigned char *data;    /* pointer to the record data */
        unsigned char *input;   /* where the decode bytes are */
        unsigned char *comp;    /* only used with decompression - malloc()ed */
        unsigned long epoch;    /* epoch number, needed by DTLS1 */
        unsigned char seq_num[8]; /* sequence number, needed by DTLS1 */
    } SSL3_RECORD;
</code></pre>

<p>可以看到，每个<code>record</code>有它的<code>type</code>、<code>length</code>和<code>data</code>，规规矩矩。</p>

<p>回到<code>dtls1_process_heartbeat</code>：</p>

<pre><code class="c">/* Read type and payload length first */
hbtype = *p++;
n2s(p, payload);
pl = p;
</code></pre>

<p>可以看到<code>SSLv3 record</code>的第一个byte就是放这个<code>heartbeat</code>的<code>type</code>。 宏<code>n2s</code> 则是从<code>p</code>里面取两个byte放到payload里面，被用来作为payload的长度。 <strong>注意这里并没有检查<code>SSLv3 record</code> 实际的长度。</strong></p>

<p>接下来在这个函数里面干了下面这些事情：</p>

<pre><code class="c">unsigned char *buffer, *bp;
int r;

/* Allocate memory for the response, size is 1 byte
 * message type, plus 2 bytes payload length, plus
 * payload, plus padding
 */
buffer = OPENSSL_malloc(1 + 2 + payload + padding);
bp = buffer;
</code></pre>

<p>可以看到，用户要多少程序就分配多少，最多可以分配到<code>65535+1+2+16</code>，指针bp被用来操作这块内存。然后：</p>

<pre><code class="c">/* Enter response type, length and copy payload */
*bp++ = TLS1_HB_RESPONSE;
s2n(payload, bp);
memcpy(bp, pl, payload);
</code></pre>

<p>宏<code>s2n</code>把<code>n2s</code>做的操作恢复出来：先拿16个bit的值放到2个byte里面，也就是原来请求的payload的长度。然后把<code>pl</code>里面放的payload(请求者提交的data)拷贝到新分配的<code>bp</code>里面。</p>

<p>看起来是很平常的操作，只不过没有认真的检查用户输入而已，但问题也就在这里了。</p>

<a name="Where.is.the.bug"></a>
<h2>Where is the bug</h2>

<p>如果用户并没有正在提交声称的那么多个bytes的payload，那么memcpy就会读到同一个process里面SSLv3 record附近的内存内容。</p>

<p>这附近有哪些内容呢？</p>

<p>首先要明白在linux上，内存的动态分配主要是通过<a href="http://linux.die.net/man/2/sbrk">sbrk</a> 或者是 <a href="http://man7.org/linux/man-pages/man2/mmap.2.html">mmap</a>。如果内存是通过sbrk分配的，它会使用<code>heap-grows-up</code>规则，泄露出来的东西不会那么多（但是如果是同时并发请求<a href="http://blog.existentialize.com/diagnosis-of-the-openssl-heartbleed-bug.html#fn:update">还是有东西会漏</a>）。</p>

<p>在这里，<code>pl</code>因为malloc里面的mmap_threshhold多半是sbrk分配的，但是，那些关键的用户数据，则多半是通过mmap分配内存。于是这些数据就会被攻击者用<code>pl</code>拿到。如果再考虑并发请求，就&hellip;</p>

<a name="The.fix"></a>
<h2>The fix</h2>

<p>所以，整个patch里面最主要的fix就是：
* 检查是否有长度为0的虚假heartbeat
* 检查record的真实长度</p>

<p>代码如下：</p>

<pre><code class="c    ">    /* Read type and payload length first */
    if (1 + 2 + 16 &gt; s-&gt;s3-&gt;rrec.length)
        return 0; /* silently discard */
    hbtype = *p++;
    n2s(p, payload);
    if (1 + 2 + payload + 16 &gt; s-&gt;s3-&gt;rrec.length)
        return 0; /* silently discard per RFC 6520 sec. 4 */
    pl = p;
</code></pre>

<a name="So."></a>
<h2>So?</h2>

<p>这个bug大概算是影响这么剧烈的bug里面最好明白的一个，所以居然我也看明白了。感受：</p>

<ul>
<li>为了可扩展性引入了复杂度，经常都会带来恶梦</li>
<li>用户的输入，无论如何都不能相信，一定要check</li>
<li>C语言的确是大牛小牛都会踩到坑啊</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[解决iowait过高的告警]]></title>
    <link href="http://172.16.121.110:4000/2014/02/hunting-the-iowait-problem-maker/"/>
    <updated>2014-02-24T09:22:00+08:00</updated>
    <id>http://172.16.121.110:4000/2014/02/hunting-the-iowait-problem-maker</id>
    <content type="html"><![CDATA[<p><img src="/downloads/images/2014_02/warning_letter.png" title="Don't touch me..." alt="warning letter" /></p>

<p>从Nagios切到<a href="https://www.zabbix.com">Zabbix</a>之后，经常大清早被iowait过高的告警邮件叫醒。因为这套Zabbix监控是本座搭的，所以解决这个问题就只有本座来了&hellip;..哎，不知道是不是把首席运营官给宠坏了。</p>

<a name="iowait........................"></a>
<h2>iowait的定义和计算方式</h2>

<p>iowait的定义为：</p>

<p><blockquote><p>iowait is time that the processor/processors are waiting (i.e. is in an idle state and does nothing), during which there in fact was outstanding disk I/O requests.</p></blockquote></p>

<p>也就是至少有一个I/O在进行时CPU处于<code>idle</code>状态的比例。</p>

<p>我们都知道用<code>vmstat</code>, <code>iostat</code>, <code>sar</code>等命令查看系统状况的时候，CPU有四种比较主要的状态：user, sys, idle和iowait。它们都是表示CPU处于此状态的一个平均比例（其中sar命令是可以用<code>-P</code>具体指定哪个CPU的，其他的命令一般是所有CPU的平均），通常相加应该就是1.</p>

<p>这个比例的统计其实是通过kernel不断的更新计数器然后计算出来的。当时钟中断发生的时候，kernel检查当前CPU是不是idle的。如果不是，就检查正在执行的指令是user space还是kernel space的。如果是user space就给<code>user</code>的计数器加1，kernel space就给<code>sys</code>计数器加1.</p>

<p>类似的，如果CPU是处于idle状态，kernel就检查是不是有I/O操作正在发生（可以是local disk也可以是<code>mount</code>的NFS），如果有就给<code>iowait</code>计数器加1，没有就给<code>idle</code>计数器加1.</p>

<p>当我们运行<code>vmstat</code>或者<code>sar</code>等命令查看时，它们会先读取当前这几个计数器的计数，然后在用户指定的时间里面等待，然后再次读取。因为用户指定的时间里面过去了多少个<code>tick</code>是可以计算的，然后前后计数器的增值也可以计算，就可以算出一个比值。比如如果用户运行的命令是<code>vmstat 2</code>，表示每两秒取样一次，那么：</p>

<ol>
<li>tick是10ms一个，所以总共是200个ticks</li>
<li>计数器的增量/200*100就是每个状态的百分比</li>
</ol>


<a name="iowait........."></a>
<h2>iowait的意义</h2>

<p>这其实比它怎么计算要难理解一些。比如本座之前心里就有一个疑问：既然只是某个process在block，那么系统会schedule其他的事情，这对性能有什么大不了的影响呢？</p>

<p>来看几个例子。</p>

<a name="L........."></a>
<h3>例子一</h3>

<p>假设一个程序进行批量的事务，每个事务都有一个10ms的计算任务，计算出的结果通过同步的方式写到磁盘。由于它写结果的文件是阻塞方式打开的，所以I/O完成之前写操作是不会<code>return</code>的。如果我们假设磁盘系统没有cache，每个物理的I/O需要20ms，那么一个事务需要30ms。也就是每秒33个事务（33 tps）。如果把系统算成只有一个CPU的话，很显然<code>iowait</code>就是66%。</p>

<p>这种情况下，如果我们能改进I/O子系统，比如启用磁盘的缓存，让每次物理的I/O只需要1ms的话，那么<code>iowait</code>就会迅速下降到8%左右。可见这种情况下，<code>iowait</code>直接影响着程序的performance。</p>

<a name="L........."></a>
<h3>例子二</h3>

<p>假设一个磁盘检查的程序运行在系统上，每秒钟读4k的数据。我们假设这个程序的入口是main()，然后读磁盘的函数是read()，main()和read()都是用户态的。read()属于libc.a，会调用kread()这个系统调用来进行物理的I/O，这个时候就进入了kernel态。整个main(),read()和kread执行的时间加起来不长，我们假设是50微秒。而物理的I/O需要多久要看seek的数据有多远，假设需要2-20ms。这样就完全有可能当时钟中断的时候，cpu是idle的，而且I/O正在发生，于是<code>iowait</code>值就达到97-98% (如果每个I/O需要20ms就是99-100%)。</p>

<p>这种情况下，虽然<code>iowait</code>数值非常高，其实这个系统的性能是正常的。</p>

<a name="L........."></a>
<h3>例子三</h3>

<p>假设有两个程序跑在同一个CPU上。一个程序写得有点儿问题，I/O会阻塞10秒左右。另一个则100%的时间都在做计算。由于当前一个程序阻塞起来的时候，后面这个程序被运行了，因此无论什么时候都没有CPU处于idle的状态等I/O，于是<code>iowait</code>一直是0，这时候其实系统的performance是有很大的问题的。</p>

<a name="L........."></a>
<h3>例子四</h3>

<p>假设系统是4核的CPU，运行了6个程序。其中4个程序有70%时间在进行物理的I/O，30%的时间在进行计算任务（假设其中25%在用户态，5%在kernel态）。另外2个程序假设100%时间都在用户态进行计算任务，没有任何I/O操作。</p>

<p>如果我们查看系统的CPU状态，大概可能看到下面的状况:</p>

<pre><code>     cpu    %usr    %sys    %iowait   %idle
      0       50      10      40       0
      1       50      10      40       0
      2      100       0       0       0
      3      100       0       0       0
      -       75       5      20       0
</code></pre>

<p>如果我们把相同的6个程序跑到一个6核的机器（相同的CPU和磁盘配置），那么可以简单的认为会有下面的结果：</p>

<pre><code>     cpu    %usr    %sys    %iowait   %idle
      0       25       5      70       0
      1       25       5      70       0
      2       25       5      70       0
      3       25       5      70       0
      4      100       0       0       0
      5      100       0       0       0
      -       50       3      47       0
</code></pre>

<p>也就是说，同样的程序跑在不同的系统上，iowait增加了一倍多，而这个时候其实没有什么performance问题，只不过是系统还能做更多的计算工作。</p>

<a name="L......"></a>
<h3>结论</h3>

<ul>
<li>CPU处于<code>iowait</code>状态，并不说明CPU不能运行其他的程序</li>
<li><code>iowait</code>偏高只能说明系统这个时刻还能进行更多的计算任务，至于是不是出现了performance问题，需要进一步分析才知道</li>
</ul>


<a name="L..........................."></a>
<h2>找出造成问题的进程</h2>

<p>虽然每次都是6点半多少说明应该是某个cron任务（因为机器上没有其他自定义的定时任务）但没法具体知道究竟是哪个。</p>

<p>最简单的办法当然是出问题的时候用<code>iotop</code>命令来看了 。</p>

<pre><code> # iotop
 Total DISK READ: 8.00 M/s | Total DISK WRITE: 20.36 M/s
  TID PRIO USER DISK READ DISK WRITE SWAPIN IO&gt; COMMAND
 15758 be/4 root 7.99 M/s 8.01 M/s 0.00 % 61.97 % bonnie++ -n 0 -u 0 -r 239 -s 478 -f -b -d /tmp
</code></pre>

<p>但是谁又会在6点多起来干这种事情。除开修改系统时间重现问题，还可以通过ps命令查看记录处于<code>D</code>状态的进程来找到。</p>

<p><code>ps</code>命令输出里面对<code>PROCESS STATE CODES</code>的定义是：</p>

<pre><code> D uninterruptible sleep (usually IO)
 R running or runnable (on run queue)
 S interruptible sleep (waiting for an event to complete)
 T stopped, either by a job control signal or because it is being traced.
 W paging (not valid since the 2.6.xx kernel)
 X dead (should never be seen)
 Z defunct ("zombie") process, terminated but not reaped by its parent.
</code></pre>

<p>处于等待I/O完成状态的进程一般就是<code>D</code>，所以可以通过tmux起一个sessio来跑下面的命令：</p>

<pre><code>    while true; do date; ps auxf | awk '{if($8=="D") print $0;}'; sleep 1; done &gt; /var/log/ps.log
</code></pre>

<p>然后在又一个这样的6点半：</p>

<p><img src="/downloads/images/2014_02/zabbix_cpu_util.png" title="Don't touch me..." alt="warning letter" /></p>

<p>去日志里面查看：</p>

<pre><code>$ cat /var/log/ps.log | grep D

root      7585  7.9  0.0   5904   812 ?        D    06:34   0:02                  \_ /usr/bin/updatedb.mlocate
root      7585  7.8  0.0   5904   812 ?        D    06:34   0:02                  \_ /usr/bin/updatedb.mlocate
root      7585  7.8  0.0   5904   812 ?        D    06:34   0:02                  \_ /usr/bin/updatedb.mlocate
root      7585  7.8  0.0   5944   944 ?        D    06:34   0:02                  \_ /usr/bin/updatedb.mlocate
root      7585  7.7  0.0   5944   944 ?        D    06:34   0:02                  \_ /usr/bin/updatedb.mlocate
root      7585  7.5  0.0   5944   944 ?        D    06:34   0:02                  \_ /usr/bin/updatedb.mlocate
root      7585  7.5  0.0   5944   944 ?        D    06:34   0:02                  \_ /usr/bin/updatedb.mlocate
root      7585  7.6  0.0   5944   944 ?        D    06:34   0:03                  \_ /usr/bin/updatedb.mlocate
root      7585  7.7  0.0   5944   944 ?        D    06:34   0:03                  \_ /usr/bin/updatedb.mlocate
root      7585  7.7  0.0   5944   944 ?        D    06:34   0:03                  \_ /usr/bin/updatedb.mlocate
root      7585  7.8  0.0   5944   944 ?        D    06:34   0:03                  \_ /usr/bin/updatedb.mlocate
root      7585  7.7  0.0   5944   944 ?        D    06:34   0:03                  \_ /usr/bin/updatedb.mlocate
root      7585  7.8  0.0   5944   944 ?        D    06:34   0:03                  \_ /usr/bin/updatedb.mlocate
root      7585  7.7  0.0   5944   944 ?        D    06:34   0:03                  \_ /usr/bin/updatedb.mlocate
root      7585  7.7  0.0   5944   944 ?        D    06:34   0:03                  \_ /usr/bin/updatedb.mlocate
root      7585  7.7  0.0   5944   944 ?        D    06:34   0:03                  \_ /usr/bin/updatedb.mlocate
root      7585  7.7  0.0   5944   944 ?        D    06:34   0:03                  \_ /usr/bin/updatedb.mlocate
root      7585  7.8  0.0   5944   944 ?        D    06:34   0:03                  \_ /usr/bin/updatedb.mlocate
root      7585  7.8  0.0   5944   944 ?        D    06:34   0:03                  \_ /usr/bin/updatedb.mlocate
root      7585  7.8  0.0   5944   944 ?        D    06:34   0:04                  \_ /usr/bin/updatedb.mlocate
root      7585  7.6  0.0   5944   944 ?        D    06:34   0:04                  \_ /usr/bin/updatedb.mlocate
root      7585  7.6  0.0   5944   944 ?        D    06:34   0:04                  \_ /usr/bin/updatedb.mlocate
root      7585  7.6  0.0   5944   944 ?        D    06:34   0:04                  \_ /usr/bin/updatedb.mlocate
root      7585  7.6  0.0   5944   944 ?        D    06:34   0:04                  \_ /usr/bin/updatedb.mlocate
root      7585  7.7  0.0   5944   944 ?        D    06:34   0:04                  \_ /usr/bin/updatedb.mlocate
root      7585  7.6  0.0   5944   944 ?        D    06:34   0:04                  \_ /usr/bin/updatedb.mlocate
root      7585  7.6  0.0   6000   968 ?        D    06:34   0:04                  \_ /usr/bin/updatedb.mlocate
root      7585  7.6  0.0   6000   968 ?        D    06:34   0:04                  \_ /usr/bin/updatedb.mlocate
</code></pre>

<p>嗯，原来是<code>/usr/bin/updatedb.mlocate</code>。Google了一下<a href="" title="http://ubuntuforums.org/showthread.php?t=1243951&amp;page=2&amp;p=7844783#post7844783">^1</a>发现其实关掉也没什么：</p>

<pre><code>sudo killall updatedb.mlocate
sudo chmod -x /etc/cron.daily/mlocate
</code></pre>

<p>整个世界清静了。</p>
]]></content>
  </entry>
  
</feed>
