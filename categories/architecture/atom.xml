<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: architecture | @Lenciel]]></title>
  <link href="http://lenciel.com/categories/architecture/atom.xml" rel="self"/>
  <link href="http://lenciel.com/"/>
  <updated>2017-04-14T11:19:13+08:00</updated>
  <id>http://lenciel.com/</id>
  <author>
    <name><![CDATA[Lenciel]]></name>
    <email><![CDATA[lenciel@gmail.com]]></email>
  </author>

  
  <entry>
    <title type="html"><![CDATA[微服务架构里的数据处理]]></title>
    <link href="http://lenciel.com/2017/02/handling-data-in-msa/"/>
    <updated>2017-02-16T02:58:52+08:00</updated>
    <id>http://lenciel.com/2017/02/handling-data-in-msa</id>
    <content type="html"><![CDATA[<p>之前说过，实践微服务架构的<a href="http://lenciel.com/2017/02/the-real-success-by-doing-msa/">最大收益</a>在于对团队的改造：我们希望构建起彼此独立，以不同技术栈和不同速度进行工作，在需求变更时能够快速响应和更新而不会相互影响，具备良好自治性的团队。根据康威定律，如果我们的组织结构进化成这样，我们的软件才可以变得符合“微服务架构”。</p>

<p>要达到这种自治性，就需要“解耦”：这个词90%念叨它的人都不知道怎么做，有一些所谓的微服务架构实践指南上甚至有“每个微服务应该有自己的数据库，两个微服务之间不能共享数据库”这样的硬性条款。乍听起来这很棒，因为你不会遇到不同的服务读写模型不同带来的各种竞争，也不会遇到不同业务需要的数据模型不同带来的冲突等等。</p>

<p>但是这样的设计也会丧失一些单一数据库的优势：比如拥有ACID属性的事务，比如更加方便完成数据的管理和变更，比如大家讨论起问题来，使用的术语比较一致。</p>

<p>那么在实践微服务架构的时候，我们如何治理数据？首先，我们需要弄清下面的问题：</p>

<ul>
<li>什么是领域？什么是现实？</li>
<li>什么是事务边界？</li>
<li>不同的服务如何跨越边界进行通信？</li>
<li>如果换种方式思考数据呢？</li>
</ul>


<a name="L.................."></a>
<h3>什么是领域？</h3>

<p>在大多数关于微服务架构的讨论中，“领域”这个关键的概念，也就是DDD（Domain Driven Design）里面的<code>Domain</code>，都是没有被提及的。</p>

<p>我们在构建一个微服务之前，首先需要搞明白它解决的领域内数据是如何流转的（包括产生和消费的数据）。比如，如果我们迁移一个叫“短信服务”的系统到微服务架构上，那么你要了解这个领域里面的数据对象和数据的流转：发送方，接收方，白名单，黑名单，消息模板，定时器等等。</p>

<p>要了解这些数据对象首先要了解它们的“现实模型”：在现实生活里面，什么是一个短信的发送方？它有什么属性？如何进行数据建模？</p>

<p>很容易想到，发送方需要有个手机号，然后呢？</p>

<p>如果你负责的是业务安全，可能会想到，需要限制发送频次吗？按天限制还是按分钟？限制是全局的还是对单个发送方生效的？如果超过了频次需要加入黑名单吗？是永久加入还是惩罚性的？</p>

<p>如果你是做别的业务，你考虑的出发点就会大大不同：在没有“为了处理什么业务来进行设计，上下文是什么”的定义之前，对任何对象都没法有一个“客观现实的定义”。</p>

<p>明确“上下文”的重要性常常被我们忽略，可能是因为人类的大脑天生可以处理上下文。人类在沟通的时候，会根据自己的判断，把歧义去掉，把话题纳入正确的上下文里面去讨论。而电脑是做不到这点的：我们必须通过在某个确定的领域下进行数据建模，来让电脑明确我们要处理的业务。</p>

<p>对一个短信的发送方进行所谓的“领域建模”是相对容易的，真正的系统设计里面，我们往往面对的是复杂度高很多的，多个数据模型组成的领域模型的构建，这个时候就需要边界。</p>

<a name="L......"></a>
<h3>边界</h3>

<p>什么时候需要划分边界？在<a href="http://dddcommunity.org/">DDD协会</a>发布的材料里面建议，围绕<a href="http://dddcommunity.org/resources/ddd_terms/">Entities、Value Objects和Aggregates</a>来进行领域建模，从而确定一个<a href="https://martinfowler.com/bliki/BoundedContext.html">有边界的上下文</a>。</p>

<p>换句话说，我们定义和优化领域模型的过程里面，就会形成一个定义这个领域的上下文的边界。这一个个边界清晰的领域可以以微服务架构里面的一个个服务来实现，边界里面的一个个组成部分又可以细化成独立的领域，再进行边界的划分和实现。</p>

<p>所以，微服务架构里面，采用DDD进行实施，确定边界，很重要。</p>

<p>注意，我们的数据模型（我们对系统中的实体按照现实生活中它的属性建立的模型）应该驱动领域模型成形，不要反过来了。</p>

<p>当我们有了领域模型，形成了边界之后，这些边界划分的粒度，也可以一定程度上体现系统的自治性。</p>

<p>你可能会问，Netflix，Twitter，淘宝等等大厂，大家都在说搞微服务，可没有谁说过什么搞DDD，为什么它很重要？</p>

<p>其实并不是这样，你看Netflix的架构师是这么说的：</p>

<blockquote><p>“People try to copy Netflix, but they can only copy what they see. They copy the results, not the process”</p>

<p>Adrian Cockcroft, former Netflix Chief Cloud Architect</p></blockquote>

<p>实践微服务框架的落地，并没有固定路径可走，每个公司都会有自己的实际情况，所以原样照搬Netflix或者任何一家公司的经验，都注定失败。</p>

<p>但这里的“实际情况”究竟是什么？为什么不能照搬？</p>

<p>有一种经常被挂在嘴边不去搞Netflix那一套的理由是，“我们不是Netflix，我们的业务没有那么复杂”。其实Netflix的业务虽然复杂，却远没有传统行业复杂：在互联网上提供流媒体服务，比起航空管理系统来说，还是要简单很多的。</p>

<p>互联网公司之所以采用微服务架构，并不在于它解决了复杂度的问题，而更多是：1. 增加和部署新功能的速度 2. 满足规模化发展的需要。就拿货车帮举例，要给一两个城市里面的司机货主配货，不那么复杂。要给几百个城市的上百万从业者配货，就没有那么容易了。</p>

<p>所以，微服务架构的实践，一定是业务领域、业务规模和组织架构的三方面需求动态平衡的结果。没有办法形成固定的套路，并不仅仅是技术方面的原因，比如系统的复杂度，而是因为每个公司在这三个方面的差别很大。</p>

<a name="L......................"></a>
<h3>什么是事务边界?</h3>

<p>我们需要DDD这样的技术来帮助我们理解我们用来实现系统的模型，并围绕模型划定有上下文的边界。在不同上下文的不同边界内，一个现实里的对象（比如发信人）可能有不同的数据模型。</p>

<p>但所有的模型和边界确定后，问题来了：数据模型表征的实体发生变化时，我们往往需要跨多个边界进行数据变更。</p>

<p>这听起来不难，但不幸的是，我们创建分布式系统的时候，仍然在使用一些错误的做法，比如通过单一的，关系型的，ACID的数据库来完成数据视图，没有仔细考虑分布式系统的异步性和网络的不稳定。</p>

<p>我们开发了各种框架来封装网络层，让我们对网络的情况一无所知（大量的RPC框架，数据库抽象层都是这么做的）。同时使用大量的同步调用的技术（REST，SOAP，各种类似CORBA的RPC框架），把remote的服务器当成local的服务器来调用。</p>

<p>我们设计的系统没有考虑自治性，而是用两段提交等方式来克服分布式系统带来的挑战。这样的思路必然带来异常脆弱的系统：无论你叫它SOA、microservice还是miniservice。</p>

<p>那么“事务边界”究竟如何定义？它是指考虑了业务变化的各种因素后，你能找到的最小的原子化单元。不管你是利用数据库的ACID特性还是两段提交来达到原子化，并不重要。重要的是我们让事务边界尽量的小，理想情况下最好一个对象一个（Vernon Vaughn有很多关于DDD Aggregates的文献里面提到了这种做法，注意这里我们说的对象也是指DDD里面的Value Objects）。</p>

<p>在一个确定的上下文里，Aggregates指的是一些Entities和Value Objects的封装，负责确保不变性。一个上下文边界里面可以有多个Aggregates。</p>

<p>比如，在开发系统的时候我们可能有下面的用例：</p>

<ul>
<li>“允许司机找货”</li>
<li>“允许司机联系某个货主”</li>
<li>“允许司机预约对某个货物承运”</li>
</ul>


<p>我们这里有三个上下文边界：搜索，联系和预约。搜索是根据出发地、目的地、价格等要素显示符合条件的货。联系是通过电话、短信等手段联系到发某条货的某个货主，进行价格的讨论。预约是司机和货主达成一致后交付少量担保金进入实际的承运流程。对不同的上下文边界，我们可以定义出不同的事务边界，来规约变量和不变量。这里我们不讨论跨上下文边界的原子事务。</p>

<p>如果我们的目标是一个较小的事务边界，我们如何来建模？可能我们会把货建模成有时间，路线，定价等Value Object和货物，货主等Entity的一个Aggregate，这个Aggregate聚合了对这些信息，可以对它完成预约。</p>

<p>这样的设计看起来很靠谱，在代码里面很容易就可以建出对应的对象模型，在数据库里面也很容易就可以建表。</p>

<p>怎么看这个边界是不是够小了？可以想想看，在我们变动一个预约里的货物信息时，是不是需要变动聚合在一起的所有值对象和实体呢？很明显你可能只需要改一下目的地，而不会动到货主：这里我们这样建模是因为这样聚合起来的数据模型比较直观方便而已，作为一个事务边界，它太大了。如果我们货物的属性，货主的属性以及预订的状态都经常发生变化，那就会产生各种事务冲突，不管你用悲观锁还是乐观锁都没用。并且这样的设计显然不好扩展，更不用说只要有一个地方出问题，就会影响大面积的业务。</p>

<p>如何我们把事务边界再放小一些呢？</p>

<p>比如把预约、货物承运信息和货物信息放到三个独立的Aggregate里面。预约仅仅封装货主和司机的信息，以及定金付款等预约相关的信息。货物是否还可以承运封装货物的运输信息。货物封装货物本身的一些属性。我们不需要这三者之间有强一致性，但是当货物被预约后，我们希望三部分都可以正确处理自己的状态：作为平台我们希望预约这个Aggregate感知交易的情况，作为货主希望可以配置和查看货物被承运的信息，作为司机希望可以查看和承运感兴趣的货物。那么我们如何去实现一个“司机找货并联系货主形成预约”的流程？</p>

<p>在预约里面，我们可以调用货物承运信息这个Aggregate，要它完成对某个货物的承运。这个预约的操作是个独立的事务，返回一个预约id。我们可以把这个预约id和这个预约关联起来，然后提交这个预约，这又是一个独立的事务，我们没有用到两段提交或者两段加锁。</p>

<p>要注意的是这里之所以可以这样处理，还是业务逻辑决定的：我们允许对一单货形成多个预约，而不是规定“从没有被预约过的货物里面选中一个预约，分配给某个司机，把它从可以找的货物列表里面去掉，不要再对这个货物进行预约”这样的业务逻辑。</p>

<p>这个简化的例子展示了我们可以怎样规划较小的事务边界。但是在很多情况下我们的数据并不是这么容易就可以处理的，比如当完成预约之后，司机和货主最终希望是形成担保交易开始进入承运环节，这就需要跨边界进行数据通信了。</p>

<a name="L...................................."></a>
<h3>如何进行跨边界的数据通信</h3>

<p>当这样的需求发生时，如何在不同的Aggregates甚至不同的上下文边界保持数据的一致性？</p>

<p>考虑这些问题时我们首先要考虑分布式系统的特性：<a href="http://queue.acm.org/detail.cfm?id=2953944">没有什么是可以预期的</a>。无论是系统里面的某个部分出问题还是网络出问题都是非常常见的。正确的做法是直面这些挑战，让你的数据模型可以在它依赖的其他部分，别的边界里包含的系统出问题的时，继续工作，并稍后修复并保证一致性。</p>

<p>在之前提到过，微服务架构里面，自治的重要性：这其实并不是一个有弹性的软件系统的需求，<a href="http://lenciel.com/2017/02/why-event-driven-when-doing-msa/">任何有弹性的系统都这样</a>。</p>

<p>所以，在事务边界和上下文边界之间，通过事件通信，来进行同步和一致性的保证。“事件”可以被看成是系统的某个局部在某个确定的时间点的快照被拍下来之后发给其他的节点。各个节点都可以监听自己感兴趣的事件，保存其中的数据，根据其中的数据做响应。</p>

<p>继续前面的例子。当预约发生后，其中某个司机和货主最终谈成了并形成担保交易，如何把这个交易落盘？这里面有一些技术细节在于，我们如何保证对数据库的写操作和往消息队列里面发消息是原子的？在这些消息被处理的时候，如果又有预约发生呢？</p>

<p>理想情况下，Aggregates会直接使用命令和<a href="http://martinfowler.com/eaaDev/DomainEvent.html">域事件</a>：每个操作被实现成命令，每个返回被实现成一个事件。这样我们就可以更清楚地把上下文边界内部使用的事件和跨域使用的事件分开。我们既可以使用一个<a href="https://geteventstore.com/">event store</a>，它既有数据库的功能也有pub-sub的消息队列的功能，也可以使用ACID数据库并把数据库的变更都通过类似<a href="http://debezium.io/">Debezium</a>复制到持久化的日志服务如Kafka里面，然后处理事件。无论是使用哪种方法，核心在于我们希望使用产生于某个时间点的immutable的事件来进行通信。</p>

<p>这样做有很多的好处：</p>

<ul>
<li>避免在不同的上下文边界上建立高成本的，甚至是不可能完成的事务模型</li>
<li>对某个系统的变更，不会影响其他系统的时序和可用性</li>
<li>系统自己可以决定对外部事件的反应速度和方式，并最终达到一致性</li>
<li>系统可以采用对自己最有效的方式进行数据存储</li>
<li>更灵活，更弹性，更好扩展</li>
<li>更容易变更数据库的schema</li>
<li>需要更加深入地学习CAP等相关技术点，来实现你的存储和消息队列</li>
</ul>


<p>当然，这样的设计也会带来：</p>

<ul>
<li>更大的复杂度</li>
<li>很难调试</li>
<li>由于拿到事件都有延迟，并且不知道系统其他部分什么时候拿到，所以不能在这方面有任何假设（这个问题各种模式都有，只是在这种模式下面特别明显）</li>
<li>更难部署和维护</li>
<li>需要更加深入地学习CAP等相关技术点，来实现你的存储和消息队列</li>
</ul>


<p>你可以看到最后一条出现了两次，这是因为无论是否使用微服务架构或者DDD，如果你对分布式系统里的并发性，一致性的基本概念和常见解决方案都没有概念，仅仅靠对数据库的ACID特性的利用来搞定当今各种系统的开发，肯定会遇到各种各样的问题。</p>

<p>另一个与此有关的有趣概念是所谓的“CQSR模式”，其核心思想是读写分离。对于大部分的互联网公司，写操作都是非常简单的，比如增加一个司机或者货主，但是读操作是千奇百怪的。而另一些公司，则是读操作非常简单，写操作特别复杂。CQRS可以很好的帮助你更好的分隔事务边界和上下文边界。</p>

<p>那如果一个服务只有一个数据库，并且这个数据库不与其他服务进行分享呢？那么它可以订阅事件流中自己感兴趣的事件，然后往其他服务共享出来的数据库添加一些数据作为事件的响应。“共享数据库”在很多地方被批评说不是一种好的实现方式，其实只要是符合场景，并没有关系。记住，实践微服务架构，没有规矩，只有权衡。比如我们的好几个服务就共用了数据库，这些服务进程都是我们的团队来维护，仍然做到了良好的自治性。</p>

<a name="L...................................."></a>
<h3>如果换种方式思考数据呢？</h3>

<p>如果我们换一种视角，把所有的东西都作为事件来处理，并且把这些事件持久化。在这种思想下，数据库，缓存，索引都可以被看作是发生在过去的事件持久化后的库存，而当前状态则是建立在这份库存基础上的系统状态的反映。</p>

<p>这样来思考和实现有下面几个好处：</p>

<ul>
<li>你可以把自己的数据库仅仅当成状态的快照来想，而不是“事实记录”</li>
<li>你可以在变更了自己的系统时，重放过去发生过的所有事件来进行验证</li>
<li>你可以在数据库的版本或者schema变更时，重放过去发生过的所有事件来进行验证</li>
<li>你可以切换到全新的技术栈，然后重放过去发生过的所有事件来进行验证</li>
</ul>


<p>更多关于这方面的内容可以看看Martin Kleppmann的<a href="http://www.confluent.io/blog/turning-the-database-inside-out-with-apache-samza/">“Turning the database inside-out with Apache Samza”</a>。</p>

<a name="L......"></a>
<h3>总结</h3>

<p>关于微服务架构的实践很容易陷入的陷阱就是一上来就选框架或者选模式：“我们RPC用Dubbo，用Zookeeper做配置中心”或者“每个服务都有自己独立的数据库”。微服务架构成功落地的关键，首先是人，然后是对数据进行仔细的研究和建模，最后才是确定框架和技术栈。</p>

<p>而如何处理数据？先做仔细的业务领域研究，进行数据建模，从而推导出领域模型，确定上下文边界。结合业务特点、业务规模、技术栈等多方面考虑，确定事务边界。尽量不做跨边界的事务操作，在自治子系统内部搞定，通过事件驱动和达成最终一致性。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[采用事件驱动实施微服务架构]]></title>
    <link href="http://lenciel.com/2017/02/why-event-driven-when-doing-msa/"/>
    <updated>2017-02-12T03:58:52+08:00</updated>
    <id>http://lenciel.com/2017/02/why-event-driven-when-doing-msa</id>
    <content type="html"><![CDATA[<a name="L......"></a>
<h3>事件</h3>

<p>我们在实践微服务架构的时候，根本目的是为了在“商业层面”拥有更加敏捷的系统：更容易响应需求变化，更容易添加、发布和尝试新功能，从而跑在竞争对手前面。</p>

<p>要做到敏捷，系统首先必须是自治的（autonomous）。自治性（autonomy）可以说是敏捷系统的一个先决条件：系统的各个部分相互之间如何沟通，当某个部分失败时如何处理和自动恢复等等，都需要自治性。自治性意味着系统的各个部分可以独立运作，对其他系统，团队和流程的依赖都可以shed：也就是说，对服务A的修改不应该影响到依赖它的服务B，A服务挂了，B服务也应该健在。</p>

<p>自治性的系统是微服务架构造就的吗？并不见得：真正成功实践了微服务架构的公司，真正重要的也不是这个技术而是组织架构上的先行。自治的系统，比如开源社区，城市，自由股票市场，甚至是一个迁徙中的鸟群，它们都不断地适应环境，响应变化，在失败案例中不断地学习。</p>

<p>这类被称为“复杂自适应系统（<a href="https://en.wikipedia.org/wiki/Complex_adaptive_system">Complex Adaptive Systems</a>）”的系统，是经过科学家专门研究，得出了很多结论的。其中很重要的一个就是，自治的系统会对“事件”作出“响应”。</p>

<p>当有事件发生时，一个自治的系统，不管是蚁群，人类组织，还是一个软件服务，会选择“做什么”或者“不做什么”，来进行响应。整个复杂的系统，都是这些事件在驱动的。这其实也很好理解，想想我们每天醒来，会根据温度穿衣；开车上班，会根据信号灯启停。我们人类的整个生活都是在对各种事件作出响应。</p>

<p>软件系统也可以被构造成这样：独立，自治，容错，可扩展。</p>

<a name="L.........................................."></a>
<h3>从授权到自治，以及最终一致性</h3>

<p>在很多分布式系统的实现里面，人们都通过创建一个单一地址空间来适应不稳定的网络环境。这是个<a href="https://en.wikipedia.org/wiki/Fallacies_of_distributed_computing">从很多方面来看都错误的做法</a>，但是它实现起来要简单一些：通过RPC调用，让remote的对象处理一些任务，或者请求一些数据。以电商里面结算购物车为例：购物车服务调用计价服务，计价服务可能会调用物流服务，根据发货地区和物流服务商等因素调整价格，同时购物车服务又会调用仓储服务来获取信息和更新货架。这就是所谓的“授权管理”模式：我们调用对数据有修改权限的服务，完成相应的操作。这种模式就意味着大量的全局状态和互斥锁，并且需要大量的事务。</p>

<p>并且，这种基于授权的设计也会导致瓶颈产生：一个服务挂掉，就容易雪崩；不同服务对数据需求不一样的时候，API越来越乱，或者产生一个大而全的统一API，提供给每个服务大量不需要的细节数据。</p>

<p>如果我们换个角度来看系统：不是依靠调用方对某个资源或者服务可以行使的权力来驱动系统，而是通过时间和时间轴上发生的事件来驱动系统，就像我们自己的实际生活一样。还是以电商的系统举例，我们的物流服务有没有可能知道目前顺丰在某个区域搞活动，使用顺丰有优惠，然后把这个数据保存在自己的数据库里面，这样每个订单产生时，这些区域的订单默认使用顺丰？如果我们的服务都这样来设计，它们的研发就不需要考虑太多依赖方当前的状态。</p>

<a name="L.................."></a>
<h3>最终一致性？</h3>

<p>通过事件驱动，而不是通过“just-in-time”的授权查询使得系统里各个服务能够更加自治，更好容错，更有弹性。但是影响复杂自适应系统的自治性的一个因素，也会影响自治的事件驱动系统，那就是时延“delays”。</p>

<p>如果你发现了某个事件已经发生，你立刻就可以做出反应。比如，有车强行变道进入你的车道，你会马上变道避让或者刹车。但是如果在“知道事件发生”这部分有时延，你的反应就没法那么迅速了，比如你正在训家里小朋友，结果没有发现有车变道进来了，就会“咣”&hellip;软件系统也一样。</p>

<p>么最终一致性指什么呢？再以购物为例。如果不是事件驱动的，那么如果你往购物车里面添加了某个商品，这时候仓储服务如果出了问题，你的查询没有返回，你就只好死等在那里。但是如果大家都使用事件驱动，你添加购物车的时候，发出了一个事件。这个时候仓储服务不在线，前端上看来，你还是把商品加入了购物车。当仓储系统恢复时，它收到之前那个事件，发现这个商品已经卖光了，这个时候它抛出一个“库存不足”的事件。购物车服务，计费服务等服务就根据当前用户的状态，去消费这个事件（如果没有结算就在结算的时候通知用户，如果已经结算就要退款或者补货等等）。这样让用户不被阻塞，并最终保持状态一致，就叫做最终一致性。</p>

<a name="L..............."></a>
<h3>需要的技术</h3>

<p>关于事件，延迟和一致性，再多说几句。事件只有在能够保证它们的时序的时候，才是可用的。也就是说，一组事件的时序，必须对于消费方来说是可信的。这涉及分布式系统里面的另外一个难题，对于构建“transactionality”也同样重要，以后再细说。但总的来说，如果事件乱序了，那么我们不做手工的修复就没有保持最终一致性。<a href="https://martin.kleppmann.com/">Martin Kleppmann</a>管这个叫做“perpetual inconsistency”。时延，乱序，是分布式系统里面的两个难题。</p>

<p><img src="/downloads/images/2017_02/two_hard_problems.jpg" title="Don't touch me..." alt="Vhost threshold" /></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[推行微服务架构的最大收益]]></title>
    <link href="http://lenciel.com/2017/02/the-real-success-by-doing-msa/"/>
    <updated>2017-02-10T17:58:52+08:00</updated>
    <id>http://lenciel.com/2017/02/the-real-success-by-doing-msa</id>
    <content type="html"><![CDATA[<p>作为行业里面最火热的名词之一，“微服务架构”在<a href="http://www.zdnet.com/article/soa-done-right-the-amazon-strategy/">Amazon</a>、<a href="http://nginx.com/blog/microservices-at-netflix-architectural-best-practices/">Netflix</a>等大厂取得的成功，大家算是耳熟能详了。</p>

<p>但是作为CTO、技术VP或者架构师，要把你服务的公司或者项目加入到“实践微服务并取得成功”的列表上，难度其实是很大的。仅仅是把自己的系统打散成多个服务，就有很大的<a href="https://www.slideshare.net/ceposta/camel-microservicesfabric8">成本</a>。所以Martin Flower也<a href="http://martinfowler.com/articles/microservice-trade-offs.html">提醒过</a>要当心入坑。</p>

<p>所以看到各种会议，博客，社交媒体上实施微服务架构的经验分享时，要明白这里面真正的成功并不在于对各种技术的应用，或者说，在成功利用Docker、Kubernets或者SpringBoot等等性感的技术之外，微服务架构带来的最大的收益并不简简单单是技术的落地。</p>

<a name="L..............."></a>
<h3>最大的收益</h3>

<p>微服务架构真正的收益在于形成小而美，能胜任各种职能的扁平化，自组织，自管理的团队，完成在传统组织架构下无法完成的拓展性和创新性工作。</p>

<a name="L....................."></a>
<h4>两个披萨的团队</h4>

<p>Amazon的“团队规模应该控制在点两个披萨就可以吃饱”的规则很有名，Jeff Bezos<a href="http://99u.com/articles/7255/the-jeff-bezos-school-of-long-term-thinking">自己说</a>：</p>

<blockquote><p>Managers: We need more communication on and between our teams
Bezos: No. Communication is terrible”</p></blockquote>

<p>要构建自组织的，创新的团队，需要的不是“更多”的沟通而是 <a href="http://blog.idonethis.com/two-pizza-team/">更有效的沟通</a>。这点说起来容易也很好听懂，但要做到其实非常难，只要看看你自己手机上那50多个工作原因拉的微信群就知道。</p>

<p>但我们可以在团队规模较小的时候开始尝试。所有人一起办公，培养起友谊和信任，产生化学反应互相激发：这样发生<a href="https://en.wikipedia.org/wiki/Groupthink">group think</a>或者<a href="https://en.wikipedia.org/wiki/Social_loafing">social loafing</a>的几率就会变小很多。</p>

<p><a href="http://hackman.socialpsychology.org/">J Richard Hackman</a>在研究了团队和组织之后指出，团队里面的人之间的沟通和人数的关系是：</p>

<blockquote><p>(n*n-1)/2</p></blockquote>

<p>如果人数n不断增加，顺畅沟通的难度就会变大，团队的效率就会降低。</p>

<p>Hackman建议的人数是10人以内，Amazon一般是6-8个人，海军陆战队是4人一个编组：也就是说，人数不需要那么死板的规定，只是应该比较少。</p>

<p>其实要感受这个不需要那么多理论，回忆一下参加一个婚礼时在餐桌上沟通的质量，和跟两三个朋友喝个茶沟通的质量对比一下，就明白小团队的优势。但我还是推荐好好读读Hackman关于<a href="http://econ.au.dk/fileadmin/Economics_Business/Currently/Events/PhDFinance/Kauttu_Why-Teams-Dont-Work-by-J.-Richard-Hackman.pdf">团队的文章</a>。</p>

<a name="L..............."></a>
<h4>多功能团队</h4>

<p>为什么我们需要一个团队有各种功能，而不是负责开发、测试、产品、运维的某个单一方面？</p>

<blockquote><p>Bad behavior arises when you abstract people away from the consequences of their actions</p></blockquote>

<p>创建团队在功能上的清晰分界，就跟告诉住宾馆的人弄脏了房间是服务员来打扫一样，是在鼓励“坏行为”的发生。一个优秀的程序员应该在编写质量上乘的代码的同时，关注可测试性、易维护性、安全性、性能、可扩展性和易用性等多个方面的问题。如果你划分了DBA、OPS、QA等职能团队，开发自然而然的就会认为自己把功能实现出来，工作就完毕了，下面的话就会出来：</p>

<ul>
<li>“我哪有时间测试，那是测试做的”</li>
<li>“数据库的变更找DBA”</li>
<li>“我只负责这个功能的实现，基础设施和运维负责它的高可用”</li>
</ul>


<p>要防止这些对话发生在你的团队，就需要引导和宣扬“一专多能”的文化。在很多成功的公司里面（Amazon，Netflix，Facebook，Google）都很强调这点，比如Amazon著名的“谁编写，谁负责”。现在行业里面很流行另外一个热词DevOps，实际上DevOps的本质是Dev在前的，甚至<a href="https://www.rallydev.com/blog/engineering/you-don-t-need-devops-team-you-need-tools-team">不应该有专职的DevOps部门</a>。</p>

<a name="L............"></a>
<h4>康威定律</h4>

<p>软件开发里面，技术问题远没有人的问题难解决。所以康威说：</p>

<blockquote><p>organizations which design systems … are constrained to produce designs which are copies of the communication structures of these organizations</p></blockquote>

<p>要如何打破内部各个团队之间的壁垒呢？除开自顶向下的进行组织架构的变更，还可以尝试内部开源。</p>

<a name="L............"></a>
<h4>内部开源</h4>

<p>一旦你打破职能壁垒，构建起小的，多职能的团队，就能够看到这些人为了构造一个高质量的软件系统，一起努力。他们的工作形态其实挺像开源组织的：大家都可以发表意见，都可以贡献代码，对最终的发布负责。</p>

<p>这样的团队形成之后，在他们的输出基本稳定成形后，就可以开始尝试内部开源。</p>

<a name="L......"></a>
<h3>总结</h3>

<p>微服务架构的各种成功案例和大家拥抱它的热切姿态，很容易让我们觉得它解决了很大的问题。</p>

<p>其实微服务架构里面很多基本指导原则，SOA里面都有。但后者最终的失败就在于，虽然技术上有一整套WS-*的规范，但是却没有在组织结构上做相应的适配，所以陷入了康威定律指出的死路。</p>

<p>技术和流程当然很重要，但是它们的推动，永远是靠人的，因此，组织结构先行，全员参与，共同为建设能够输出高质量系统，快速响应需求变更的团队努力， 这才是实践微服务架构或者DevOps对一个公司最大的收益。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Web应用开发的七项原则]]></title>
    <link href="http://lenciel.com/2014/11/7-principles-of-rich-web-applications/"/>
    <updated>2014-11-17T22:30:42+08:00</updated>
    <id>http://lenciel.com/2014/11/7-principles-of-rich-web-applications</id>
    <content type="html"><![CDATA[<p>本文源自Guillermo Rauch的<a href="http://rauchg.com/2014/7-principles-of-rich-web-applications/">7 Principles of Rich Web Application</a>，经过他本人授权，我翻译了放在这里。</p>

<p>这篇文章主要介绍构建使用Javascript来控制UI的网站在设计时的7个原则。它们是我作为一名开发人员的经验所得，也是我作为一名互联网资深用户的体会和总结。</p>

<p>Javascript毫无疑问早已成为了前端开发人员不可或缺的工具。但现在它的使用范围还在不断扩展到其他的领域，比如<a href="http://nodejs.org/">服务器端</a>甚至是<a href="https://tessel.io/">微控制器</a>。在斯坦福这样的声望卓越的大学里面，它也已经被选为计算机科学<a href="http://web.stanford.edu/class/cs101/">入门课程</a>的教学语言。 </p>

<p>即便如此，它在web开发中究竟应该扮演什么样的角色或者说负责哪方面的作用，仍然是个迷：即便对于很多框架和类库的作者而言也是如此：</p>

<ul>
<li>JavaScript应该被用来替代像<code>history</code>，<code>navigation</code>和<code>page rendering</code> 这样的浏览器函数么？</li>
<li>服务器端开发是不是到头了？是不是根本就不该在服务器端渲染HTML了？</li>
<li>Single Page Applications (SPAs) 是不是代表着未来的趋势?</li>
<li>一个网站和一个Web应用之间的区别精确的描述起来究竟是什么? 是不是应该就是一个东西?</li>
<li>在网站上，JS应该用来 <em>增强</em> 页面的效果，而在Web应用中，则被用来 <em>渲染</em> 整个页面?</li>
<li>是否应该使用像PJAX或者TurboLinks这样的技术?</li>
</ul>


<p>下面就是我试着回答这些问题做的一些分析。我的分析是通过用户体验(UX)层面，特别是如何最小化用户拿到他们感兴趣的 <em>数据</em> 的时间，作为切入点，来验证对Javascript的 <em>各种</em> 使用方式。我会从网络通信的基础入手，一直说到对未来趋势的预测。</p>

<ol>
<li><a href="#server-rendered-pages-are-not-optional">Server渲染页面仍然是必须的</a></li>
<li><a href="#act-immediately-on-user-input">对用户输入立刻响应</a></li>
<li><a href="#react-to-data-changes">数据变更时的应对</a></li>
<li><a href="#control-the-data-exchange-with-the-server">控制与服务器的数据交互</a></li>
<li><a href="#dont-break-history-enhance-it">不要破坏history，增强它</a></li>
<li><a href="#push-code-updates">推送代码更新</a></li>
<li><a href="#predict-behavior">行为预测</a></li>
</ol>


<a name="L1..Server...............................a.name..server-rendered-pages-are-not-optional....a."></a>
<h2>1. Server渲染页面仍然是必须的<a name="server-rendered-pages-are-not-optional"></a></h2>

<p><strong>TL;DR</strong>: <em>服务器端渲染与SEO无关，它主要的考虑是性能：需要考虑的包括不在服务器渲染的话，请求脚本、页面样式、页面资源和API请求造成的额外的开销，以及考虑在HTTP2.0里加入的<code>PUSH of resources</code></em>.</p>

<p>首先需要指出，在业界有一种错误的二分法："server-rendered apps" 和 &ldquo;single-page apps"的对立。如果我们的目标是用户体验和性能的最优化，那么选择其中任何一个而抛弃另一个都是错误的决定。原因其实很明显：整个互联网用于传输页面的介质，有一个理论上可计算的速度局限。关于这点，Stuart Cheshire有个著名的文献 (或者说是吐槽？)，<a href="http://rescomp.stanford.edu/~cheshire/rants/Latency.html">“It’s the latency, stupid”</a> :</p>

<p><blockquote><p>The distance from Stanford to Boston is 4320km.<br/>The speed of light in vacuum is 300 x 10<sup>6</sup> m/s.<br/>The speed of light in fibre is roughly 66% of the speed of light in vacuum.<br/>The speed of light in fibre is 300 x 10<sup>6</sup> m/s * 0.66 = 200 x 10<sup>6</sup> m/s.<br/>The one-way delay to Boston is 4320 km / 200 x 10<sup>6</sup> m/s = 21.6ms.<br/>The round-trip time to Boston and back is 43.2ms.<br/>The current ping time from Stanford to Boston over today’s Internet is about 85ms (…)<br/>So: the hardware of the Internet can currently achieve within a factor of two of the speed of light.</p></blockquote></p>

<p>这里提到的从波士顿到斯坦福路上花费的85ms，当然会随着时间的推移不断的改善：如果你现在测试一下说不定已经大大增速了。但需要注意很重要的一点：就算达到了光速，这两个海岸间最少也需要 <strong>50ms</strong> 才能完成通信。</p>

<p>换句话说，用户间连接的带宽再怎么显著提高，花在传输路上的延迟总有无法突破的速度极限。所以，在页面上显示信息时减少请求次数，也就是减少信息被传输在路上的次数，对于良好的用户体验和出色的响应速度而言，至关重要。</p>

<p>这一点在Javascript驱动的Web应用流行起来之后显得尤为明显。这些应用一般<code>&lt;body&gt;</code>标签内什么东西都没有，只有<code>&lt;script&gt;</code>和<code>&lt;link&gt;</code>标签，被称为"Single Page Applications"或者"SPA"。就像它的名字所暗示的一样，服务器返回时一直在重用同一个页面，其他的页面内容都是在客户端被处理和渲染的。</p>

<p>考虑下面的这个场景：用户在浏览器上访问<code>http://app.com/orders/</code>，如果这是一个传统的网页，那么在后台处理这个请求的时，就会带回重要的 <em>信息</em> ，用来完成页面的显示：比如，从数据库里面查询出订单，然后把它们的数据放在请求的返回里面。但如果这是一个SPA，那么第一次可能会立刻返回一个包含<code>&lt;script&gt;</code>标签的空页面，然后再跑一趟才能拿回用来渲染页面的内容和数据。</p>

<p><img src="/downloads/images/2014_11/spa_code_breakdown.png" title="SPA code breakdown" alt="SPA code breakdown" />
图1. 服务器端发送的SPA的每个页面组成结构分析</p>

<p>目前大多数的开发者都大方接受了这个额外的 <em>网络传输过程</em> 是因为他们确信这只发生一次：后面反正是有cache的。也就是说，大家形成了这么一个共识，既然整个代码包一旦加载一次，就可以不用再请求其他的脚本和资源就完成对绝大多数的用户交互（包括跳转到应用的其他页面）的处理，那么这个开销就是可以接受的。</p>

<p>但实际上，虽然有cache，脚本解析和执行的时间仍然会带来性能上的下降。<a href="http://modernweb.com/2014/03/10/is-jquery-too-big-for-mobile/">“Is jQuery Too Big For Mobile?”</a> 这篇文章就探讨了即便是加载一个jQuery库，就会花去一些浏览器数百毫秒的时间。</p>

<p>更糟糕的是，和以前网速慢那种图片慢慢加载的效果不同，如果是脚本正在加载，用户什么都看不到：在整个页面被渲染出来之前，只能显示空白的页面。</p>

<p>最重要的是，目前互联网数据传输主要的协议TCP <em>建立</em> 比较慢。</p>

<p>首先，我们知道，一个TCP连接先需要握手。如果处于安全考虑使用了SSL，就还需要额外的两个来回（客户端重用了session的话，也需要一个额外的来回）。这些流程完毕之后，服务器才能开始往客户端发送数据。换句话说，再小的代码包实际上也需要几个来回才能完成传输，这就让前面描述的问题变得更加糟糕。</p>

<p>其次，TCP协议里面有一个流控机制，被称为 <code>slow start</code>，也就是在连接建立过程中逐渐增加传输的分段(<code>segments</code>)大小，入下图所示：</p>

<p><img src="/downloads/images/2014_11/tcp_segments_chart.png" title="TCP segments chart" alt="TCP segments chart" />
图2. 服务器端在TCP连接的不同阶段能够发送的分段大小(KB)</p>

<p>这对SPA有两个很大的影响：</p>

<ol>
<li><p>文件比较大的脚本，花在下载上的时间比你想象中的要长得多。Google的Ilya Grigorik在他的专著<a href="http://chimera.labs.oreilly.com/books/1230000000545/ch02.html#thats_four_rou">“High Performance Browser Networking”</a> 里面说过，“4个来回(…)和数百毫秒的延迟都花在从服务器下载64KB的文件到客户端上了”，从前面的图也可以看到，基本是比较高速的网络连接，比如伦敦和纽约之间，一个TCP连接要达到最大速度，也需要花上大概225ms。</p></li>
<li><p>因为前面说的延迟对首个页面访问也是有效的，所以你让什么数据最先被传输就显得非常重要了。Paul Irish在他的演讲<a href="https://docs.google.com/presentation/d/1MtDBNTH1g7CZzhwlJ1raEJagA8qM3uoV7ta6i66bO2M/present#slide=id.g3eb97ca8f_10">“Delivering the Goods”</a>给出的结论是，一个Web应用最开始的 <strong>14kb</strong> 数据是最重要的。</p></li>
</ol>


<p>在足够短的时间窗内完成内容传输（哪怕只是呈现基本的没有数据的layout）的网站，就是响应良好的。这也是为什么对于很多习惯了在服务器端处理数据的软件开发者觉得Javascript很多时候根本没必要用，或者是在很有限的情况下用用就行了。当这些开发者使用的是配置良好的服务器和数据库，又有CDN来做部署和分发时，他们这种感觉会非常明显。</p>

<p>但是，服务器在辅助和加速页面内容的分发和渲染中应该被怎么使用，也是需要根据每个应用场景仔细分析的，绝对不是“把整个页面交给服务器渲染吧”那么简单的事情。在一些情况下，如果页面上的内容对用户并不是非看不可的，就可以不放在第一个响应中返回，而是让客户端在后面的操作中到服务器去取。</p>

<p>比如，有的应用会先把一个"壳"页面返回给客户端，然后在这个页面上并发的请求多个部分的数据。这样即使在后台连接速度较慢的情况下，仍然能够有较好的响应速度。还有的应用会把 “<a href="http://www.feedthebot.com/pagespeed/prioritize-visible-content.html">浏览器里面的第一个整屏</a>” 显示的页面做预渲染。</p>

<p>服务器能够根据当前处理的<code>session</code>，用户和URL对脚本和样式文件进行分类也是很重要的。举例来说，用来对订单进行分类的脚本，对于<code>/orders</code>这个URL显然是重要的，而处理"首选项"的逻辑的脚本就不那么重要。再比如说，我们可以对CSS样式表进行分类，比如区分“结构性的样式”和“皮肤和模板的样式”等。前面这类很可能对Javascript的正确运行是必须的，因此需要 <em>阻塞</em> 的方式加载， 后面这类则可以用异步的方式加载。</p>

<p>到目前为止，在服务器端处理一部分或者所有的页面，仍然是避免过多客户端与服务器的交互的主要手段。<a href="http://danlec.com/blog/stackoverflow-in-4096-bytes">StackOverflow in 4096 bytes</a>很不错地展示了如何降低和服务器的来回交互次数。作为概念验证的SPA，它理论上可以做到在握手后的第一个TCP连接中完成加载！当然，要做到这些，它使用了<a href="http://www.chromium.org/spdy/link-headers-and-server-hint">SPDY 或者 HTTP/2 server push</a>，因此可以在一个hop里面传输所有客户端可以缓存的代码。</p>

<p><img src="/downloads/images/2014_11/st4k.png" title="StackOverflow clone in 4096 bytes" alt="StackOverflow clone in 4096 bytes" /></p>

<p>图3. 使用了内链CSS和JS技术的<code>Stackoverflow in 4096 bytes</code></p>

<p>如果我们有一个足够灵活的系统，可以在浏览器和服务器直接共享渲染页面的代码（比如双方都是js），并且提供工具增量的加载脚本和样式，那么 <em>网站</em> 和 <em>Web应用</em> 就可以合一而不再是两个模棱两可难以区分的词了：它们本身就有一样的UX要素。比如一个博客页面和一个复杂的CRM，都有URL，都需要跳转，都展示数据，本质上并没有太大不同。即便是像数据表格这样复杂的东西，传统上主要是客户端提供的功能来完成对数据的处理，但也首先需要给用户展示那些需要他处理的数据 。降低客户端和服务器交互的次数，对实现我们说的这样的系统非常重要。</p>

<p>在我看来，我们看到的大量系统上采用了这样那样性能上的权宜之策，是因为整个技术栈的复杂度在不断累加。Javascript和CSS这样的技术是被逐渐加入到系统的，它们的风靡又花了一段时间。尽管有人希望在协议上做出改进，来增强性能（比如SPDY或者QUIC），但应用层显然才是最需要改进的地方。</p>

<p>要理解速度的重要性，去重温一下WWW和HTML创立之初的一些讨论是非常有用的。特别是在1997年提议在HTML里加入<code>img</code>这个标签的时候，Marc Andreessen在<a href="http://1997.webhistory.org/www.lists/www-talk.1993q1/0260.html">下面这个邮件thread</a>里反复强调了提供信息的速度有多么重要： </p>

<p><blockquote><p>“If a document has to be pieced together on the fly, it could get arbitrarily complex, and even if that were limited, we’d certainly start experiencing major hits on performance for documents structured in this way. This essentially throws the <strong>single-hop principle of WWW</strong> out the door (well, IMG does that too, but for a very specific reason and in a very limited sense) — are we sure we want to do that?”</p></blockquote></p>

<a name="L2..............................a.name..act-immediately-on-user-input....a."></a>
<h2>2. 对用户输入立刻响应<a name="act-immediately-on-user-input"></a></h2>

<p><strong>TL;DR</strong>: <em>我们可以使用JavaScript来掩盖网络的延迟，把它作为设计原则，就可以在你自己的应用里面去掉绝大多数的<code>spinner</code>或者<code>loading</code>。使用PJAX和TurboLink的话，你就会失去了这些改善用户速度体验的机会。</em>.</p>

<p>第一个原则里，在描述为什么要尽量减少前端和后端之间数据来回传输的次数时，主要是基于传输速度有理论上限的事实。实际上另一个需要考虑的要素就是网络的质量。我们都知道，当网络连接状况不好时，就会有数据包需要被重传。所以，你觉得应该一个来回就传输完毕的数据，可能实际上要花去好几个。</p>

<p>在这方面，Javascript正好可以帮上忙：通过客户端的代码来驱动UI，人工的构造出零延迟，就可以<em>掩盖网络的延迟</em>，制造一切操作都很顺畅的假象。比如，网页和网页之间是通过超链接，<code>&lt;a&gt;</code>标签，链接在一起的。传统网页上，当一个链接被点击时，浏览器就发送一个可能会耗时很久的请求，然后处理请求并把内容呈现给用户。</p>

<p>但Javascript允许你<strong>立刻响应</strong>（有些地方把这个叫<strong>乐观响应</strong>）：当一个链接或者按钮被点击时，页面立刻做出响应而不需要去访问网络。这方面著名的例子就是Gmail（包括最近Google的新产品Inbox）的"邮件归档"功能。当你点击"归档"，UI上邮件立刻会被显示为归档状态，而服务器的请求和处理是异步进行的。</p>

<p>再比如，我们处理的是一个表单。也许你觉得一个表单在数据被提交到服务器，处理结果返回之前，不能做太多的事情。但其实当用户完成输入并点击提交的时候，我们就可以开始响应了。甚至有些做到极致的应用，比如Google搜索页面，当用户开始输入的时候，展示搜索结果的页面就已经开始渲染了。</p>

<p><img src="/downloads/images/2014_11/google_homepage.gif" title="Google Homepage" alt="Google Homepage" /></p>

<p>图4. Google在用户输入搜素关键字时就开始渲染搜索结果页面</p>

<p>这种行为被称为 <em>layout adaptation</em>。 它的思路是当前页面知道操作后状态的页面layout，所以在没有数据填充的情况下，它就可以过渡到下面那个状态的layout。这样的处理是"乐观"的，是因为有可能后面那个页面的数据一直没有返回，而这时候页面的layout已经画在那里了。</p>

<p>Google的主页的演进，非常清楚的说明了我们这里强调的第一和第二个原则。</p>

<p>首先，分析访问<code>www.google.com</code>时TCP连接的<a href="https://gist.github.com/guille/3e1b2d7529009370b986">包数据</a>可以看到整个首页的数据都被一次性发出来了。整个交互，包括关闭连接，耗时几十毫秒而已。而且，似乎在Google<a href="http://en.wikipedia.org/wiki/Google#mediaviewer/File:Google1998.png">一开始的版本</a>就做到了这点。</p>

<p>在2004年晚些时候, Google<a href="http://googleblog.blogspot.com/2004/12/ive-got-suggestion.html">标杆性地</a>使用了JavaScript完成<code>输入时动态提示</code>功能（和Gmail一样，也是一个20%创新时间产出的项目），这一功能也启发了很多网站开始大量的使用<a href="http://www.adaptivepath.com/ideas/ajax-new-approach-web-applications/">AJAX</a>:</p>

<p><blockquote><p>Take a look at Google Suggest. Watch the way the suggested terms update as you type, almost instantly with no waiting for pages to reload. Google Suggest and Google Maps are two examples of a new approach to web applications that we at Adaptive Path have been calling Ajax</p></blockquote></p>

<p>到了2010年，Google又<a href="http://googleblog.blogspot.com/2010/09/search-now-faster-than-speed-of-type.html">推出了</a><em>及时搜索</em>，也就是我们前面看到的效果：当用户输入关键字时，整个页面无需刷新就可以展示搜索的结果。</p>

<p>另一个例子是iOS。在很早期的版本，iPhone就要求开发者提供一个<code>default.png</code>图片，用来在应用被加载完成之前显示给用户:</p>

<p><img src="/downloads/images/2014_11/iphone_default_png.png" title="iPhone default" alt="iPhone default" /></p>

<p>图5. iPhone OS强制在应用加载前显示一个default.png</p>

<p>当然，这里OS不是在隐藏网络延迟，而是CPU处理延迟。对于iPhone初期版本来说，这样来弥补硬件的弱点非常重要。当然就和网页上使用提前加载一样，这种手法有可能会崩坏：当加载来的数据和<code>default.png</code>不匹配的时候。Marco Arment在2010年对它可能带来的影响进行了 <a href="http://www.marco.org/2010/11/11/my-default-png-dilemma">透彻的分析</a>。</p>

<p>除开处理表单和输入，Javascript还被大量用于处理<strong>文件上传</strong>。我们可以通过各种前端表现来满足用户上传文件的需求：拖拽，粘贴以及各种file picker。特别是有了<a href="https://developer.mozilla.org/en-US/docs/Using_files_from_web_applications">HTML5的新API</a>之后，我们可以在文件完成传输前就显示它的信息。在Cloudup网站的上传文件中，就使用了类似的实现。从图片中可以看到，在用户选择了文件之后，缩略图就立刻生成并显示在用户界面上了：</p>

<p><img src="/downloads/images/2014_11/cldup_upload.gif" title="Cloudup upload" alt="Cloudup upload" /></p>

<p>图6. 在上传完成前图片就被显示出来并且加入了虚化效果</p>

<p>上面的方式都是采用前端技术来制造<em>速度的假象</em>，但这种方式其实在很多地方都被证明是有效的。<a href="http://www.nytimes.com/2012/08/19/opinion/sunday/why-waiting-in-line-is-torture.html">一个例子</a>是在美国休斯顿机场，通过<em>增加</em>到达乘客走到行李提取处的距离，而不是实际上的行李处理速度，就大大的<em>减少</em>了旅客抱怨行李领取太慢的问题。</p>

<p>运用了这种设计原则的应用，使用<code>spinners</code>或者<code>loading</code>提示符来提醒用户页面正在刷新的场景会非常少出现。整个页面的动线，都应该被<em>实际数据</em>来驱动。</p>

<p>当然，立即响应这个原则也不能被滥用。在特定的用户交互场景下，立即响应是有害的：比如用户在注销或者是支付的流程中，我们当然不能让他"乐观"的认为没有真正完成的操作已经完成了。但即使在这些场景下，使用<code>spinners</code>或者<code>loading</code>提示符也不应该<strong>被提倡</strong>。 只有在你觉得应该提醒用户这个操作会非常长，你可以去干别的事情时，才应该显示它们。那是多长？在UX设计中经常被引用的<a href="http://www.nngroup.com/articles/response-times-3-important-limits/">Nielsen的研究报告</a>上是这么说的：</p>

<p><blockquote><p>The basic advice regarding response times has been about the same for thirty years Miller 1968; Card et al. 1991:<br/>0.1 second is about the limit for having the user feel that the system is reacting instantaneously, meaning that no special feedback is necessary except to display the result.<br/>1.0 second is about the limit for the user’s flow of thought to stay uninterrupted, even though the user will notice the delay.Normally, no special feedback is necessary during delays of more than 0.1 but less than 1.0 second, but the user does lose the feeling of operating directly on the data.<br/>10 seconds is about the limit for keeping the user’s attention focused on the dialogue. For longer delays, users will want to perform other tasks while waiting for the computer to finish.</p></blockquote></p>

<p>像PJAX或者TurboLinks这样的技术，则很大程度上完全不具备提前渲染状态迁移后下一个页面的基础layout的能力。只有当服务器端的返回传输到客户端，客户端才能开始响应。</p>

<a name="L3...........................a.name..react-to-data-changes....a."></a>
<h2>3. 数据变更时的应对<a name="react-to-data-changes"></a></h2>

<p><strong>TL;DR</strong>: <em>当服务器的数据变化时，应该主动让用户知道。这样可以使得用户无需经常进行手动的刷新(F5, Cmd+R&hellip;.)，也是一种性能上的改进措施。新的挑战是：(重)连接的管理，状态的一致性问题</em>.</p>

<p>第三个原则就是当数据源(一般是一个或者多个数据库)的数据有变更时，UI要<em>主动响应</em>。</p>

<p>给用户一个当前数据的静态的HTML快照，直到用户刷新页面（传统网页）或者操作页面元素（AJAX）已经逐渐变得过时。你的UI应该是<strong>自刷新</strong>的。当数据节点不断增加，我们设计时需要开始考虑包含手表、电话的各种移动设备和可穿戴设备时，这点尤其重要。</p>

<p>以Facebook初期对newsfeed的实现为例，因为用户都是用PC机在更新状态，把它实现成静态的网页未尝不可：一般来说，人们一天更新一次就差不多了。但现在我们生活在一个人们拍照后可以立刻分享，朋友们可以立刻发表评论的时代，对数据变化的实时响应成为了应用开发的基础需求。这不仅仅是因为我们的应用程序是多用户并发访问的，即便就考虑单用户的场景，实时更新也是很重要的。以用笔记本分享我们手机上的照片的场景为例：</p>

<p><img src="/downloads/images/2014_11/concurrent_data_points.gif" title="Concurrent Data Points" alt="Concurrent Data Points" /></p>

<p>图7. 即便是单个用户操作的场景，更好的响应性也能带来体验的提升</p>

<p>有的数据，比如<strong>Session和登录状态的同步</strong>，在多个页面间应该是非常实时的同步的。这样，当用户打开了多个tab，从其中的任何一个登出，其他的所有页面都应该登出。这点对保护用户的隐私是非常重要的，特别是我们有些设备是多个人在同时使用。</p>

<p><img src="/downloads/images/2014_11/login_sync.gif" title="Login synchronization" alt="Each page reacts to the session and login state" /></p>

<p>图8. 不同的页面间同步登录状态</p>

<p>一旦你的用户习惯了你的应用的数据是自动更新的，那么你就要考虑一个新的需求：<strong>状态一致性</strong>。当客户端收到一个原子的数据更新时，必须考虑即便在断网很长时间之后，也能够正确的完成更新。比如，你的笔记本突然没电了，几天后再打开，应用的数据是不是还正确？</p>

<p><img src="/downloads/images/2014_11/twitter_data_reconciliation.png" title="twitter数据一致性" alt="twitter数据一致性" /></p>

<p>图9. 长时间断线后重连的情况下twitter的页面</p>

<p>是不是能够保持数据的一致性也会影响你的应用在第一条原则上的表现。如果你想对首次请求的数据做优化，必须要考虑如果是断线后重连，那么第一个请求应该首先需要重新建立session。</p>

<a name="L4....................................a.name..control-the-data-exchange-with-the-server....a."></a>
<h2>4. 控制与服务器的数据交互<a name="control-the-data-exchange-with-the-server"></a></h2>

<p><strong>TL;DR</strong>: <em>接下来主要讨论的是如何精细的控制客户端和服务器之间的交互。注意出错处理，自动重试，在后台同步数据并管理好离线的缓存。</em></p>

<p>在互联网初期，客户端和服务器间的交互还仅仅有下面几种方式:</p>

<ol>
<li>点击一个连接，会触发 <code>GET</code> 来获取一个新页面并重新渲染页面</li>
<li>提交一个表单，会触发一个 <code>POST</code> 或 <code>GET</code> 并重新渲染页面</li>
<li>嵌入一个图片或者对象，会触发一个异步的 <code>GET</code> 并重新渲染页面</li>
</ol>


<p>这个模型以其简洁性显得很具吸引力，但是我们今天要明白服务器和客户端之间的数据交互，学习曲线就陡多了。最大的问题在第二点，如果不能在不刷新页面的情况下提交数据，毫无疑问是一个性能上的弱点。更重要的是，它会使得回退键不可用：</p>

<p><img src="/downloads/images/2014_11/annoy_artifact.png" title="Annoy Artifact" alt="Possibly the most annoying artifact of the old web" /></p>

<p>图10. 老一代网页上最让人讨厌的东西</p>

<p>把网站作为<strong>应用平台</strong> 来考虑，没有Javascript将是不可想象的事情。AJAX单单是在表单信息提交这方面，就让交互体验产生了一次<em>飞跃</em>。我们现在更是有了一堆各式各样的API (<code>XMLHttpRequest</code>, <code>WebSocket</code>, <code>EventSource</code>以及更多其他的) 来更好地更细致的控制数据流。不但可以在用户输入的时候就开始处理用户数据，还能够有机会提供更好的UX体验。其中一个和前面那个原则有关的UX体验上的改进就是显示当前<em>连接状态</em>。如果我们的用户觉得数据是应用自己去刷新不需要他手动操作，那么就应该显示<em>连接中断</em>以及<em>正在重试连接中&hellip;</em>等状态。</p>

<p>当发生连接中断时，最好先把数据存在内存（或者更好的，存到<code>localStorage</code>），以便在网络恢复后重新发送。 就像在<a href="http://jakearchibald.com/2014/using-serviceworker-today/">ServiceWorker</a>的介绍中提到的那样, 可以让Javascript应用在<em>后台运行</em>。</p>

<p>除开断网，当发送数据出现超时或者是错误时，也可以试着<strong>自动重试</strong>，只在确认无法成功了之后，才将问题抛给用户感知。当然，有些特别的错误还是需要额外小心的处理。比如一个<code>403</code>错误，通常说明用户的session过期了。这种情况下就该让用户重新登录，而不是继续重试了。</p>

<p>还要注意使用这种模式时，要屏蔽用户中断数据流的操作。这种操作有两种，第一种也是最明显的一种是用户尝试关闭当前页面，这种情况可以通过<code>beforeunload</code>这个<code>handler</code>来处理。</p>

<p><img src="/downloads/images/2014_11/before_unload_warning.png" title="Before unload warning" alt="The beforeunload browser warning" /></p>

<p>图11. 页面关闭之前弹出警告</p>

<p>另一种（不那么明显的）是那些触发页面转换的操作。比如点击页面上的链接，触发一个新的页面载入。这种时候你可以显示自己的弹出窗口。</p>

<a name="L5..............history.............a.name..dont-break-history-enhance-it....a."></a>
<h2>5. 不要破坏history，增强它<a name="dont-break-history-enhance-it"></a></h2>

<p><strong>TL;DR</strong>: <em>不使用浏览器来管理URL跳转和history，将带来新的挑战。我们必须保证用户在浏览时，应用的表现符合他的期望。可以自建缓存来提高响应速度。</em></p>

<p>即使不考虑表单的提交，而是设计一个仅有超链接的Web应用，也需要考虑让前进/后退导航变得更可用。比如典型的<code>infinite pagination scenario</code>，也就是应用应该允许用户在页面上随便跳转，它的实现通常需要使用Javascript监听对链接的点击，然后注入数据或者HTML（还有个可选的步骤是调用<code>history.pushState</code>或者是<code>replaceState</code>，但不幸的是很多人都不没有使用它们）。</p>

<p>这就是我使用“破坏”来形容它的原因：在Web被设计之初，这种监听对链接的点击并注入数据的情况，并不在设计图景中，而是每个状态的变迁都需要URL的变化来驱动。但虽然这种既有模式被Javascript“破坏”了，另一方面，通过使用Javascript控制history，也出现了<em>提升</em>的机会。</p>

<p>一种提升的做法是Daniel Pipius提出的所谓<a href="https://medium.com/joys-of-javascript/beyond-pushstate-building-single-page-applications-4353246f4480">Fast Back</a>:</p>

<blockquote><p>回退应该很快；用户默认数据不会有很大的变化，应该能很快回到上个页面。</p></blockquote>

<p>我们可以近似的把回退按钮认为是一个在应用每个页面都可用的按钮，然后使用原则2来设计它：<em>对用户输入立刻响应</em>。这里要考虑的关键就变成了如何缓存前一个页面以便很快能再次渲染出来。接下来你就还可以想想原则3：如何在数据有了变化时，让用户感知到这些变化。</p>

<p>另外，有一些场景下，你没法控制缓存的行为。比如，如果用户在你渲染一个页面的时候跳到第三方网站上去了，然后他按回退键。这个时候就会遇到下面的这个bug：</p>

<p><img src="/downloads/images/2014_11/back_button_bug.gif" title="Back Button Bug" alt="Pressing back incorrectly loads the initial HTML from the pageload" />
图12. 按回退键时载入了原始页面的HTML而不是刷新后的</p>

<p>另一种破坏性的操作是忽略 <em>scrolling memory</em>。和之前那个问题一样，如果页面没有JS或者其他人工的history管理，多半就不会有这个问题。但局部动态刷新的页面多半就会遇到：我测试了最著名的Javascript驱动的网站，它们的newsfeeds都有<em>scrolling amnesia</em>的问题：</p>

<p><img src="/downloads/images/2014_11/back_button_bug.gif" title="Scrolling Amnesia" alt="Infinite pagination is usually susceptible to scrolling amnesia" /></p>

<p>图13. 滚动失忆问题</p>

<p>最后，要注意哪些状态应该被持久化。比如是不是需要展开显示文章的评论：</p>

<p><img src="/downloads/images/2014_11/back_button_bug.gif" title="Scrolling Amnesia" alt="Infinite pagination is usually susceptible to scrolling amnesia" /></p>

<p>图14. 在操作history来导航时，是否展开显示评论也被持久化了</p>

<p>因为是在应用内使用超链接触发的页面重渲染，用户的期望是回到这页时，他之前展开的评论树仍然是展开的。这个状态其实是<em>瞬态的</em>， 仅仅在history栈上的这页有这个状态。</p>

<a name="L6.....................a.name..push-code-updates....a."></a>
<h2>6. 推送代码更新<a name="push-code-updates"></a></h2>

<p><strong>TL;DR</strong>: <em>数据自动更新但代码的更新不是自动推送的应用是低效的。要避免API出错，增强性能。使用无状态的DOM来避免重画。</em></p>

<p>让你的应用能够对<em>代码变更</em>进行推送是至关重要的。</p>

<p>首先，这样可以减少出错的可能并增强稳定性。当你的后台接口改变时，客户端的变更是<em>必须的</em>，否则客户端就没法处理服务器来的新格式的数据，或者上报一堆服务器没法理解的旧格式的数据。</p>

<p>考虑到原则3，代码更新的推送还有一个重要的原因：传统的网站，刷新页面一方面是为了加载新的数据，另一方面也常常是为了加载新的代码。一旦你的UI让用户觉得数据是自动刷新的，他们就不会有意识的再去刷新页面。这样仅仅有一套数据推送的机制是不够的，特别是考虑到现今很多应用一个页面要被打开很长的时间。</p>

<p>如果服务器本身有notification通道，那么可以在代码需要更新的时候推送通知给用户。如果没有，可以在客户端请求的HTTP头里面带一个版本号。服务器检查这个版本号，根据情况看要不要拒绝客户端的请求并要求它更新。</p>

<p>有了这些，应用就可以在加载数据或者代码时不再需要用户自主进行页面刷新了。比如，当一个页面<a href="https://developer.mozilla.org/en-US/docs/Web/Guide/User_experience/Using_the_Page_Visibility_API">不可见</a>，表单的输入没有被填写的时候。</p>

<p>但更好的做法是进行所谓的<strong>代码热重载</strong>。 这主要是指整个页面不需要进行重刷，而是特定的<em>模块</em>被替换并重新执行代码逻辑。</p>

<p>在很多已有的代码基础上要实现代码热重载是困难的。但从架构上把<em>行为</em>（代码）和<em>数据</em>（状态）隔离，也是非常值得考虑和探讨的。如果能这样解耦，就能很轻松的进行很多本来复杂的修改。</p>

<p>比如，你的应用需要建立一个事件总线（比如<a href="http://socket.io/">socket.io</a>）。当总线接收到事件时，某个特定的模块就改变自己的行为，比如，根据新的数据状态来产生不同的DOM内容。</p>

<p>理想状态下，我们能够以单个模块的粒度来更新代码。也就是说，仅仅因为要更新代码，没必要断开现有的socket连接。这样理想的代码能够热重载的架构就是<em>模块化</em>的。但是这里带来的挑战是模块的更新不能带来意料之外的副作用，为了实现这点，像<a href="http://facebook.github.io/react/">React</a>这样的优秀的框架被创造出来。当一个模块的代码更新后，它的代码逻辑能够静静地重新运行一次来更新DOM。 这方面的一些解释可以看看Dan Abramov的<a href="http://gaearon.github.io/react-hot-loader/">文章</a>.</p>

<p>从根本上来说，代码热重载可以极大程度上帮助你基于DOM渲染页面。特别是当状态保持在DOM里面，或者是事件响应都是你自己手工创建的时候，更新代码是一个非常复杂的事情。</p>

<a name="L7...............a.name..predict-behavior....a."></a>
<h2>7. 行为预测<a name="predict-behavior"></a></h2>

<p><strong>TL;DR</strong>: <em>通过行为预测来进一步减少延迟。</em></p>

<p>一个Javascript的应用可以有预测<em>用户输入</em>的机制。</p>

<p>最常见的办法是在数据请求的动作被真正触发之前就进行数据的预获取。比如在用户hover到链接上而不是真正点击链接的时候就开始取数据。</p>

<p>另一个比较复杂的预测用户行为的办法是通过监听用户鼠标的运动，分析它的轨迹来预测它可能会去到的”可以操作元素“，比如是按钮。下面是一个<a href="https://medium.com/@cihadturhan/a-ux-idea-i-know-where-you-are-aiming-3e00d152afb2">jQuery的例子</a>:</p>

<p><img src="/downloads/images/2014_11/behavior_predict.gif" title="I know where you're aiming" alt="jQuery plugin that predicts the mouse trajectory" /></p>

<p>图12. jQuery鼠标运动轨迹预测插件</p>

<a name="L.......a.name..conclusion....a."></a>
<h2>结论<a name="conclusion"></a></h2>

<p>网络过去和现在都是信息传递最通用的媒介。当我们不断让我们的页面变得更动态时，也要注意在引入新的特性时，能保持历史上确定的一些好的用户体验准则。</p>

<p>互相用超链接集结在一起的页面是各种类型的应用的组成单位。当用户浏览页面时，渐进地加载代码、样式表和标记，可以在保证性能的基础上不牺牲太多的交互性。</p>

<p>Javascript带来了新的契机，一旦被全面采用，将可以在保证最佳的用户体验基础上，构建前所未有的最广阔最开放的应用平台。</p>
]]></content>
  </entry>
  
</feed>
