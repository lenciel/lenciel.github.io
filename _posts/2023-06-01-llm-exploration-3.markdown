---
layout: post
comments: true
description: "我读书的时候，国内的人工智能集中在自动化专业。当时我感觉自动化专业主要有三拨人：
- 搞控制理论的，主要是用数学工具在矩阵推导；
- 搞应用系统的，主要是想要做出国产的工控机；
- 搞算法的，主要是遗传算法、神经网络；

前面两帮人是主流，彼此不太看得上，但是他们一起看不上搞算法的。到了今天，人工智能在很多学校已经和计算机、自动化平起平坐，有自己的学院了。
"
title: "LLM 调研（3）- 历史"
date: 2023-06-01 22:11:16 +0800
categories: 
- AI
- LLM
- llm-exploration
---

> 本系列是，[LLM 调研](/categories/llm-exploration/)...说一下我对它的看法，以及它能做什么不能做什么

前面的两篇聊完，有些同学觉得我很不待见 LLM。其实在使用各种 AIGC 产品的过程中，我还是觉得惊喜不断的：它的确是会造成深远影响的技术进展（大部分这类技术会符合所谓的「阿拉玛定律」[^3]，即「短期被高估，长期被低估」）。

只不过，目前看到的很多讨论落入了我们讨论这类问题反复落入过的陷阱：

- 语言本身的歧义和模糊带来的理解和交流上的困难——这就是「人工智能之父」[明斯基](https://en.wikipedia.org/wiki/Marvin_Minsky)说的「[Suitcase Words](https://news.ycombinator.com/item?id=10028306)」问题[^0]；
- 今天各个领域的 AIGC 能做的事情非常「窄」，用一些「指标」的提升去证明类似于逻辑、思维等「泛化能力」的涌现[^1]，这种论证方法是错误的，认为它带来 AGI 更是无稽之谈；
- 还有一部分人根本没有研究过 LLM ，连误解都谈不上，只是在跟风吆喝——这就是我的偶像费曼[调侃过](https://en.wikipedia.org/wiki/Cargo_cult_science)的「[Cargo Cult](https://en.wikipedia.org/wiki/Cargo_cult)」问题[^2]；

这篇我们就来回顾一点 AI 的历史，这样才好看清楚 LLM 究竟取得了什么进展，还有什么样的局限。

<h3>目录</h3>

- TOC
{:toc}

### 历史

#### 人工智能（Artificial Intelligence） 

我[写过一点](/2016/03/alphago-and-ai/#%E6%99%AE%E9%80%9A%E4%BA%BA%E7%9A%84%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD)人工智能的历史：这个术语被正式落到纸上，是 1956 年的达特茅斯会议的[提案](http://people.csail.mit.edu/brooks/idocs/DartmouthProposal.pdf)。

今天看这个寥寥数页的提案，仍能感觉各种壮志，但也能看到各种壮志仍然未酬。

- 比如 John McCarthy 在导言里就讲了要通过模拟**「神经元」**让机器学会使用人类语言；
- 比如 Allen Newell 和 Herb Simon 在里面就提出了让机器下棋、证明数学定理、具备人类的学习和解决问题能力等课题；

Allen Newell 甚至在会议后不久预测，十年内计算机就能下棋超过人类——我们现在知道，其实花了四十年，才有了深蓝。

而且，在达特茅斯会议前，虽然没有「AI」的提法，学界已经有一些关于「机器与智能」的讨论。

其中最著名的，是图灵在 1950 年 10 月发表的论文《[Computing Machinery and Intelligence](https://academic.oup.com/mind/article/LIX/236/433/986238)》[^4]。图灵琢磨这个是因为他在 [Intelligent Machinery](http://people.csail.mit.edu/brooks/idocs/IntelligentMachinery.pdf) 里提出了「discrete controlling machines」[^5]之后，就开始思考如何造出一台在运动和思维上都能全面模仿人的机器[^6]。

今天看这个寥寥数页的提案，仍能感觉各种壮志，但也能看到各种壮志仍然未酬。

比如图灵认为到了 2000 年，会有像人一样思考的机器[^7]。他甚至给出了这个机器的开发工作量是 36000 个人月——我们现在知道，2000 年又过去了二十多年，花在上面的人月应该是图灵说的几万倍了，我们还没有摸到边。

大牛们的估计出现这么大的偏差，是因为当时对人工智能涉及的两个主要领域，计算机和人，很难有正确的认知。

认知的不同，导致人工智能研究者分裂成了以「符号主义」和「连接主义」为主[^8]的数个阵营：

- 「符号主义（Symbolicism）」，又称逻辑主义，主张用符号、公理和逻辑体系搭建一套人工智能系统；
- 「连接主义（Connectionism）」，又叫仿生学派，主张模仿人类的神经元，用神经网络的连接机制实现人工智能；

##### 符号主义与专家系统

###### 优势

「符号主义」里的「符号」，就是表示客观事物或者事物间关系的「字符串」。通过它们对人类的「认知」进行编码，形成可逻辑演算的系统，是「符号主义」的核心思想。

因此，「符号主义」的核心特点在于：
- 推理的过程是可解释的；
- 出现错误，是可以追溯和定位的；
- 符号化方法对于知识的表达能力强，能够应对较复杂的知识推理；

这些优势让「符号主义」在 AI 领域长期一枝独秀，被广泛地运用于「自动定理证明」和「专家系统」的构建。尤其是「专家系统」的成功开发与应用，为人工智能走向工程应用做出了杰出贡献。

###### 不足

但「符号主义」也有一些根深蒂固的困境。比如，[哥德尔不完全性定理](https://en.wikipedia.org/wiki/G%C3%B6del%27s_incompleteness_theorems)（证明了对于任何一个公理化系统，都存在此公理体系所无法判定真伪的命题），就让使用「符号主义」构建的系统面临泛化的问题。再比如，既然要用符号来表达事物和事物之间的关系，这里就有一个谁可以把客观世界抽象成这些符号，并解释给其他人的问题。家姐在第一篇文档里留言说的「[中文屋](https://cloud.tencent.com/developer/news/365176)」，其实就是针对这个困境的一个思想实验。

因为这些没法解决的问题，「人工智能」曾经有很长一段时间发展得并不算好。我读书的时候，国内的人工智能集中在自动化专业[^8]。当时我感觉自动化专业主要有三拨人：
- 搞控制理论的，主要是用数学工具在矩阵推导；
- 搞应用系统的，主要是想要做出国产的工控机；
- 搞算法的，主要是遗传算法、神经网络；

前面两帮人是主流，彼此不太看得上，但是他们一起看不上搞算法的。到了今天，人工智能在很多学校已经和计算机、自动化平起平坐，有自己的学院了。

这似乎全靠「神经网络」的大获全胜。

##### 连接主义与神经网络

###### 历史

我们基本上听不到「连接主义」，只听得到这个门派的代表作：「神经网络」，即通过模仿人类的神经元组网，实现人工智能。

需要注意的是，它说的神经元是 1943 年生理学家麦卡洛克(McCulloch)和数理逻辑学家皮茨(Pitts)创立的脑模型，即 [MP 模型](https://towardsdatascience.com/mcculloch-pitts-model-5fdf65ac5dd1)，跟今天我们对脑神经的认知有很大的不同。但报导 ChatGPT 的媒体好像很喜欢配一张现代科学理解下的大脑透视图，显得这套东西多么先进甚至科幻。

实际上，神经网络提出快 90 年了，并且曾多次被主流圈子抛弃。比如 Marvin Minsky，虽然他 1954 年的博士论文你看标题就知道很「[连接主义](https://searchworks.stanford.edu/view/970633)」，但两年后参加达特茅斯大会时，他已经改旗易帜，成了「符号主义」领袖。

60 年代，虽然已经有学者搞出了单个神经元的[简单模型](https://news.cornell.edu/stories/2019/09/professors-perceptron-paved-way-ai-60-years-too-soon)，但 69 年，作为「符号主义」的领军人物，Marvin Minsky 和 ​​Seymour Papert 出版了一本书《[Perceptrons](https://direct.mit.edu/books/book/3132/PerceptronsAn-Introduction-to-Computational)》，从
下面这张图我们就知道，它对连 XOR 运算都不会的神经网络判了死刑：

![perceptrons_can_not_do_xor.png](/downloads/images/2023_05/perceptrons_can_not_do_xor.png --alt Don't touch me...)

到了 1980 年，有人在神经网络里面加入了一点反馈，也就是输出端检测到的错误向后传播给网络，被称为「Back-Propagating」。又过了 6 年，David Rumelhart、Geoffrey Hinton 和 Ronald Williams 发表了一篇论文《[Learning Representations by Back-Propagating Errors](https://www.nature.com/articles/323533a0)》，重振了这个领域，但不久又变得无人问津。零零星星有人实验通过增加神经网络的层数来提升指标，但因为每层都是独立的，笨重且不可控，没有改变神经网络半死不活的状态。

直到 2006 年，Geoffrey Hinton 和 Ruslan Salakhutdinov 发表了《[Reducing the Dimensionality of Data with Neural Networks](https://www.science.org/doi/10.1126/science.1127647)》，通过使用「clamping」对每层进行增量化的训练，来大大减少了数据维数。此后，神经网络渐入佳境。

这里花这么多篇幅介绍这些历史，是想说，**今天的神经网络，是曲折艰辛的理论研究，加上摩尔定律带来的硬件性能提升和互联网带来的海量数据等综合因素作用下爆发的**，而不是我们真的对大脑神经网络的工作原理有了突破[^9]。

这也就造成了这种方法的一些先天不足。

###### 不足

「连接主义」最大的问题是不具备「符号主义」的可解释性。

前面说了，AI 领域里面有很多 [Suitcase Words](https://news.ycombinator.com/item?id=10028306)，比如「学习」、「深度」或「智能」，很容易给不明就里的人造成误会，以为模型的输出是基于知识「深思熟虑」后做出的反馈。

其实，「机器学习」这个概念最早由 Arthur Samuel 1959 年在论文「[Some Studies in Machine Learning Using the Game of Checkers](https://ieeexplore.ieee.org/document/5392560)」里明确提出[^10]。文章里的「学习」主要是两个动作：

- [memoization](https://en.wikipedia.org/wiki/Memoization)
- 调参数权重

这跟通常意义下人类进行的「学习」[^11]，有很大的不同。认为「机器学习」是说机器搞学习，和认为跟自己说下午会飞过来的朋友，是像孙悟空一样飞过来一样，核心问题是还没见过什么是飞机。

再比如「深度学习」里面的「深度」，主要就是指神经网络的层数比较多，跟逻辑上或者思维上多么有「深度」完全没有关系。

所以，包括 LLM 在内的动辄几十个亿几百个亿参数的模型，在指标上，具有强大的功能和性能，但它们在逻辑上是不透明的，也是不可调试的。这就意味着我们要用它们做出一些严肃的决定，比如金融、医疗、军事、自动驾驶等方面的决定，风险是非常高的，并且有一些伦理上的问题。

了解完这些，我们就能真正聊清楚，作为神经网络在自然语言领域的有一个重大突破，LLM 到底有了什么样的进展。

[^0]: 这个术语的来源是对「行李箱」的类比，即一些词汇会将许多复杂的、不同的概念、过程和实体打包在一起，这种抽象使得我们在交流复杂思想和事物时更容易，但同时也可能导致理解上的困难和歧义，因为这些词汇并没有明确的指代。这个概念在认知科学、心理学和语言学领域都有应用，特别是在我们尝试理解和交流抽象和复杂概念时。
[^1]: 「涌现（Emergence）」这个术语本身是一个跨学科概念，并不限于人工智能。它旨在描述由局部相互作用引发的全局性质的现象，被用于研究复杂系统，如物理学、生物学、社会科学等领域。
[^2]: 「Cargo Cult」 是一种在南太平洋某些岛屿上的宗教运动。这些岛上的居民迷信地认为，如果他们模仿现代化国家的各种仪式和行为（如建立类似跑道的结构，制作木头喷气式飞机模型等），他们就可以吸引神秘力量，让现代化的科技和物资，从天而降到岛上。后来它被用作隐喻，指盲目地跟随和模仿，但却没有理解其中根本原因的行为。
[^3]: 「[阿玛拉定律](https://thevirtulab.com/what-is-amaras-law/)」 是[帕洛阿尔托未来研究所](https://www.iftf.org/)的总裁 Roy Amara 提出的：「我们往往会高估一项技术的短期影响，而低估其长期影响」。过去一些划时代的技术，如电脑、GPS 等，都出现过类似的高开低走，长期低迷，最后被普遍采用的几个阶段。
[^4]: 这篇论文介绍了「模仿游戏」，后来被当作一部纪念他的[电影的名字](https://movie.douban.com/subject/10463953/)，很多人不知道，其实这个游戏就是所谓的「图灵测试」。图灵估计，在 2000 年，一台拥有 128MB 内存（他表示为 10 的 9 次方）的计算机将有 70% 的机会可以骗过人类。
[^5]: 这就是所谓的「图灵机」，所以说图灵其实「定义」了我们今天所谓的「计算机」。此后冯·诺依曼等人提出了实现通用图灵机的体系架构，即「冯·诺伊曼架构」，或者说更公平地应该被称为「普林斯顿架构」，被使用至今。
[^5]: 他当时的结论是，传感器和运动系统会成为长期掣肘，所以应该从智能开始。并且他指出，最佳的突破口是密码学和游戏，其次是语言翻译和数学。
[^6]: 但图灵在这篇文章的结尾说了「We can only see a short distance ahead, but we can see plenty there that needs to be done」，太厉害了。
[^7]: 其实图灵在 1948 年英国国家物理实验室的内部报告中，就区分了「embodied intelligence」和「disembodied intelligence」，一个从统计学出发，一个从逻辑推导出发，为后来的分裂埋下了伏笔。另外这里省略了一些不那么被广泛讨论的分支，比如以研究机器人为主的「行为主义（Actionism）」。
[^8]: 国外计算机软硬件怎么造，和造出来之后怎么用，一般放一个专业，都在计算机系。
[^9]: 实际上，对只有 302 个神经元的秀丽隐杆线虫，我们都还没有彻底整明白它的系统究竟是如何运行的。所以[这样](https://news.umich.edu/zh-hans/%E5%AF%86%E6%AD%87%E6%A0%B9%E5%A4%A7%E5%AD%A6%E7%A0%94%E7%A9%B6%E8%80%85%E5%B1%95%E7%8E%B0%E7%A5%9E%E7%BB%8F%E5%85%83%E5%A6%82%E4%BD%95%E6%89%A7%E8%A1%8C%E5%A4%9A%E9%A1%B9%E4%BB%BB%E5%8A%A1/)或者[这样](https://zhidx.com/p/332265.html)的研究才被看成突破。
[^10]: 这兄弟的主业其实是做 IBM 的商用机，但是因为这个主业他获得了比当时绝大多数科研人员都丰富的一个资源：无限机时。他在上面编写下跳棋的程序，开创了很多今天 AI 的前沿性研究。如果再结合「强化学习」的先驱，图灵的同事 [Donald Michie](https://en.wikipedia.org/wiki/Donald_Michie) 的[相关工作](https://people.csail.mit.edu/brooks/idocs/matchbox.pdf)，可以说整个这方面的进步驱动力都是来自于大家觉得计算机「好玩」。
[^11]: 实际上，人类自己的「学习」也很多元，学跑步和学围棋，完全不是一种「学习」。